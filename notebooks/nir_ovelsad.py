# -*- coding: utf-8 -*-
"""NIR_ovelsad.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14325p9n4b25bC0RBRolVGAI_T78jPAoC

# ПРОЕКТ НИР

## Библиотеки (без версий)
"""

!pip install catboost

from google.colab import drive
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_predict
from catboost import CatBoostClassifier
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, roc_auc_score
from sklearn.utils import resample
from sklearn.base import clone
from scipy.stats import pointbiserialr, spearmanr
import shap

"""## Загрузка данных"""

drive.mount('/content/drive')

data = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/НИР/База ДКА увеличенная.xlsx')

data.head()

"""## Знакомство с данными

### Описание колонок

1.  **N пп** - номер пациента
2.  **Дата рождения**
3.  **ИБ** - история болезни, удалить
4.  **тип СД (1-1, 2-2, 3 -др)** -тип сахарного диабета
5.  **Возраст (на текущий момент)**
6.  **Пол (0 - Ж, 1 - М)**
7.  **Дата текущего ДКА** (диабетический кетоацидоз) - когда заполняли данные для данного пациента
8.  **Длительность СД (сахарный диабет) (лет)** - сколько лет диабету
9.  **Возраст манифестации СД** (сахарный диабет) - когда впервые возник диабет
10. **Вид инсулинотерапии (1 - ручки, 2 - помпа) на момент ДКА**, нуль у тех, кто дебютировал, то есть еще не кололся
11. **Применение НМГ (непрерывный мониторинг глюкозы) (0 - нет, 1 - да)** - означает, есть ли датчик в пациенте (ненужная фигня, сказали)
12. **Суточная доза инсулина**
13. **Тяжелые гипогликемии в анамнезе (0 - нет, 1 - да)** (бесполезная строка)
14. **Количество эпизодов легких гипогликемий в неделю** (бесполезная строка)
15. **Количество ДКА в анамнезе**
16. **ХБП, С** - хроническая болезнь почек, скорость клубочковой фильтрации, С это класс
17. **ХБП, А** - хроническая болезнь почек, потеря альбумина, А это класс
18. **Невролог** - 1-есть полинейропатия, 0 - нет
19. **Ретинопатия (0 - нет, 1 - непролиферативная, 2 - препролиферативная, 3 - пролиферативная)** - осложнение на глаза, цифры - это формы
20. **Целевой HbA1c** (гликированный гемоглобин, рекомендация, бесполезная фича)
21. **HbA1c** (гликированный гемоглобин в реал лайф)
22. **Креатинин при поступлении**
23. **Мочевина при поступлении**
24. **pH при поступлении**
25. **ВЕ при поступлении**
26. **Лактат при поступлении**
27. **Калий при поступлении**
28. **Натрий при поступлении**
29. **Глюкоза при поступлении**
30. **Общий холестерин**
31. **ЛПНП** - липопротеиды низкой плотности
32. **ЛПВП** - липопротеиды высокой плотности
33. **ТГ** - триглицериды (опасный жир)
34. **Сутки, на которые произошла нормализация рН** - нету, но будет позже, должно по крайней мере..
35. **Степень тяжести ДКА**
36. **Алкоголь за сутки до ДКА (0 - нет, 1 - да)**
37. **Употребление ПАВ за сутки до ДКА (0-нет, 1 - да)** - психоактивные вещества
38. **Шкала депрессии Бека** - не знаем, будет ли
39. **Опрос о страхе гипогликемии** - не знаем, будет ли
40. **CV** - коэффициент вариации
41. **Время нахождения в диапазоне ниже 4 ммоль/л (%)** - не знаем, будет ли, т.к. показатель для тех, у кого 1 в применении НМГ
42. **GMI (%)** - не знаем, будет ли, т.к. показатель для тех, у кого 1 в применении НМГ
43. **TAR1 (%)** - не знаем, будет ли, т.к. показатель для тех, у кого 1 в применении НМГ
44. **TAR2 (%)** - не знаем, будет ли, т.к. показатель для тех, у кого 1 в применении НМГ
45. **TIR (%)** - не знаем, будет ли, т.к. показатель для тех, у кого 1 в применении НМГ
46. **TBR1 (%)** - не знаем, будет ли, т.к. показатель для тех, у кого 1 в применении НМГ
47. **TBR2 (%)** - не знаем, будет ли, т.к. показатель для тех, у кого 1 в применении НМГ
48. **Данные о смерти** 1-смерть, nan - достоверно неизвестно (лучше не учитывать, наверное)
49. **Рецидив (0 - единичный, 1 - рецидив)** - таргет
"""

### сразу удаляем неинформативные колонки типа номера истории болезни, пациента
data = data.drop(['N пп', 'ИБ'], axis=1)

### посмотрим на типы колонок
data.dtypes

"""У некоторых колонок присутствуют несостыковки, позже исправим"""

### Проверка на дубликаты
data.duplicated().sum()

### избавляемся от дубликатов
data = data.drop_duplicates().reset_index(drop=True)
duplicates_count = data.duplicated().sum()
print(f"Дубликатов осталось: {duplicates_count}")

print(f'Всего колонок: {data.shape[1]}')
print(f'Всего данных (строк): {len(data)}')

### проверим количество пропусков в каждой из колонок, а также число их уникальных значений для первого взгляда на данные
missing_values = data.isna().sum()
if missing_values.sum() > 0:
    print('Есть пропуски:')
    columns_with_missing = missing_values[missing_values > 0]
    print(columns_with_missing)

    print('\nКоличество уникальных значений для колонок с пропусками:')
    for col in columns_with_missing.index:
        unique_count = data[col].nunique()
        print(f'{col}: {unique_count} уникальных значений')

    print('\nНет пропусков у колонок:')
    columns_without_missing = missing_values[missing_values == 0].index.tolist()
    print(columns_without_missing)
else:
    print('Пропусков нет')

print(f'\nВсего строк: {data.shape[0]}')

"""У всех колонок есть пропуски"""

### Удаляем колонки с более чем 160 пропусками, может быть и будет заполнено потом врачами, но сейчас это неинтерпретируемо
columns_to_drop = missing_values[missing_values > 160].index.tolist()
print(f'Колонки с более чем 160 пропусками: {columns_to_drop}')

data = data.drop(columns=columns_to_drop)
data.head()

### не вижу смысла оставлять дату рождения, это практически полная мультиколлинеарность между данной и колонкой возраста на текущий момент
print(data['Дата рождения'].astype('int64').astype('float64').corr(data['Возраст (на текущий момент)']))
data = data.drop('Дата рождения',axis=1)

### бесполезно учитывать строки с пропуском в целевой переменной
data = data.dropna(subset=['Рецидив (0 - единичный, 1 - рецидив)'])

### на данный момент я не буду учитывать колонки с пропусками 105+, считаю, что это слишком большая нехватка данных
### я бы не учитывал 25+ пропусков, однако не хочется терять столько полезных колонок
missing_values = data.isna().sum()
columns_to_drop_2 = missing_values[missing_values > 105].index.tolist()
print(f'Колонки с более чем 100 пропусками: {columns_to_drop_2}')

data = data.drop(columns=columns_to_drop_2)
data.head()

print(f"\nВсего строк: {data.shape[0]}")
print(f"Всего колонок: {data.shape[1]}")

# Series с пропусками
missing_count = data.isnull().sum()
missing_percent = (missing_count / len(data) * 100).round(2)

# df с пропусками + % от общего числа строк
missing_df = pd.concat([missing_count, missing_percent], axis=1, keys=['Количество', 'Процент %'])
print("\nСтатистика пропусков:")
missing_df.sort_values(by='Количество', ascending=False)

data.isnull().sum()

"""## АНАЛИЗ КАЖДОЙ КОЛОНКИ + ЗАПОЛНЕНИЕ ПРОПУСКОВ

### 1 - тип СД (1-1, 2-2, 3 -др)
"""

### 1. тип СД (1-1, 2-2, 3 -др)
col = 'тип СД (1-1, 2-2, 3 -др)'
data[col] = data[col].astype('category')

print(data[col].value_counts())
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')

fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# Столбчатая диаграмма с процентами
total = len(data)
value_counts = data['тип СД (1-1, 2-2, 3 -др)'].value_counts()
bars = axes[0].bar(value_counts.index.astype(str), value_counts.values)
axes[0].set_title('Распределение типа СД')
axes[0].set_xlabel('Тип СД')

# Добавляем проценты
for bar, count in zip(bars, value_counts.values):
    height = bar.get_height()
    axes[0].text(bar.get_x() + bar.get_width()/2., height + 0.5,
                f'{count}\n({count/total*100:.1f}%)', ha='center')

# Круговая диаграмма
axes[1].pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%')
axes[1].set_title('Доли типа СД')

# Столбчатая диаграмма с таргетом
sns.countplot(data=data,
              x='тип СД (1-1, 2-2, 3 -др)',
              hue='Рецидив (0 - единичный, 1 - рецидив)',
              ax=axes[2])
axes[2].set_title('ТИП СД vs Рецидив')
axes[2].set_xlabel('ТИП СД')
axes[2].legend(title='Рецидив')

plt.tight_layout()
plt.show()

# Расчет процентов рецидива по типам СД
for sd_type in sorted(data['тип СД (1-1, 2-2, 3 -др)'].unique()):
    subset = data[data['тип СД (1-1, 2-2, 3 -др)'] == sd_type]
    total_count = len(subset)
    relapse_count = int(subset['Рецидив (0 - единичный, 1 - рецидив)'].sum())

    if total_count > 0:
        relapse_percent = relapse_count / total_count * 100
        print(f"Тип СД {int(sd_type)}: {relapse_count}/{total_count} = {relapse_percent:.1f}% рецидивов")
    else:
        print(f"Тип СД {int(sd_type)}: 0 пациентов")

"""### 2 - Возраст (на текущий момент)"""

### 2. Возраст (на текущий момент)
col = 'Возраст (на текущий момент)'
print(col)
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')

print('\nСтатистика:')
print(data[col].describe())
data[col].value_counts()

plt.style.use('seaborn-v0_8-darkgrid')
fig, axes = plt.subplots(1, 3, figsize=(20, 5))

# Статистика для выбросов
Q1, Q3 = data[col].quantile([0.25, 0.75])
IQR = Q3 - Q1
lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR
outliers = ((data[col] < lower) | (data[col] > upper)).sum()


# 1. Ящик с усами
sns.boxplot(y=data[col], ax=axes[0])
axes[0].set_title(f'Ящик с усами: {col}')
axes[0].text(0.01, 0.9, f'Выбросы: {outliers}\nГраницы: [{lower:.1f}, {upper:.1f}]',
             transform=axes[0].transAxes, fontsize=10, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))


# 2. Гистограмма с выделением выбросов
sns.histplot(data[col], bins=20, kde=False, ax=axes[1])
# Закрашиваем области выбросов
axes[1].axvspan(data[col].min(), lower, alpha=0.3, color='red')
axes[1].axvspan(upper, data[col].max(), alpha=0.3, color='red')
axes[1].set_title(f'Гистограмма: {col}')
axes[1].set_xlabel(col)
axes[1].set_ylabel('Частота')
axes[1].text(0.05, 0.95, 'Красным выделены выбросы',
             transform=axes[1].transAxes, fontsize=9, color='red')


# 3. Плотность распределения с выделением выбросов
sns.kdeplot(data[col], fill=True, ax=axes[2])
# Закрашиваем области выбросов
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], data[col].min(), lower, color='red', alpha=0.3)
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], upper, data[col].max(), color='red', alpha=0.3)
# Линии границ
axes[2].axvline(lower, color='red', linestyle='--', alpha=0.7)
axes[2].axvline(upper, color='red', linestyle='--', alpha=0.7)
axes[2].set_title(f'Плотность распределения: {col}')
axes[2].set_xlabel(col)
axes[2].set_ylabel('Плотность')
axes[2].text(0.05, 0.95, f'Границы: {lower:.1f} | {upper:.1f}',
             transform=axes[2].transAxes, fontsize=9, color='red')


plt.tight_layout()
plt.show()


print(f"Выбросы: {outliers} из {len(data)} ({outliers/len(data)*100:.1f}%)")
print(f"Границы выбросов: [{lower:.2f}, {upper:.2f}]")

"""### 3 - Пол (0 - Ж, 1 - М)"""

## 3. Пол (0 - Ж, 1 - М)

col = 'Пол (0 - Ж, 1 - М)'
print(data[col].value_counts())
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')


fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# Круговая диаграмма
value_counts = data[col].value_counts()
labels = ['Женский' if i == 0 else 'Мужской' for i in value_counts.index]
axes[0].pie(value_counts.values, labels=labels, autopct='%1.1f%%')
axes[0].set_title('Доли полов')

# Столбчатая диаграмма с таргетом
plot = sns.countplot(data=data,
                     x=col,
                     hue='Рецидив (0 - единичный, 1 - рецидив)',
                     ax=axes[1])
axes[1].set_title('Пол vs Рецидив')
axes[1].set_xlabel('Пол')
plot.set_xticks([0, 1])
plot.set_xticklabels(['Женский', 'Мужской'])
axes[1].legend(title='Рецидив')

plt.tight_layout()
plt.show()

"""Это булева колонка"""

data['Пол (0 - Ж, 1 - М)'] = data['Пол (0 - Ж, 1 - М)'].astype(bool)

"""### 4 - Дата текущего ДКА"""

## 4. Дата текущего ДКА
col = 'Дата текущего ДКА'
print(col)
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')


print('\nСтатистика:')
print(data[col].describe())
data[col].value_counts()

"""На мой взгляд, это не данные временного ряда, я бы удалил вовсе эту колонку, но, допустим, оставим только год, потому что больше половины данных маскируется  как год, а не отдельная дата."""

data['Дата текущего ДКА'] = pd.to_numeric(data['Дата текущего ДКА'].astype(str).str[:4])
data['Дата текущего ДКА']

## Дата текущего ДКА
col = 'Дата текущего ДКА'
print(col)
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')


print('\nСтатистика:')
print(data[col].describe())
data[col].value_counts()

"""**УДАЛЯЕМ**"""

data = data.drop('Дата текущего ДКА', axis=1)

"""### 5 - Длительность СД (лет)"""

### 5. Длительность СД (лет)
col = 'Длительность СД (лет)'
print(col)
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')

print('\nСтатистика:')
print(data[col].describe())
data[col].value_counts()

"""Явно числовой формат, надо поменять, также запомнить, что **0 это ДЕБЮТ**, видимо впервые наблюдается по данному случаю в больнице или что-то в этом роде"""

# Находим строки, которые содержат буквы
mask = data['Длительность СД (лет)'].dropna().astype(str).str.contains('[а-яА-Яa-zA-Z]', na=False)

data.loc[mask.index[mask], 'Длительность СД (лет)'] = '0'

data['Длительность СД (лет)'].value_counts()

"""Пусть все будет в годах, так как у всех остальных месяцы не учитываются, то учитывать их у двух пациентов не вижу логичным

"""

data['Длительность СД (лет)'] = data['Длительность СД (лет)'].astype(float)
data.loc[data['Длительность СД (лет)'] < 1, 'Длительность СД (лет)'] = 0
data['Длительность СД (лет)'].value_counts()

### проверим мульиколлинеарность
data_copy = data.copy()
data_copy['Длительность СД (лет)'] = pd.to_numeric(data_copy['Длительность СД (лет)'], errors='coerce')
data_copy['check'] = data_copy['Длительность СД (лет)'] + data_copy['Возраст манифестации СД']
data_copy['check']

corr = data_copy['Возраст (на текущий момент)'].corr(data_copy['check'])
corr

data_copy[data_copy['check'] != data_copy['Возраст (на текущий момент)']]

"""Это мультиколлинеарность, так как длительность сд - это сколько человек болеет диабетом, а возраст манифестации сд - это тот возраст, в котором диабет проявился, как болезнь, что в сумме даст возраст на текущий момент, есть некоторые несовпадения, пропуски или мб ошибки ввода, заполнения, не знаю точно, как лучше поступить"""

data_copy = data_copy.dropna(subset=['Возраст манифестации СД'])
data_copy['Возраст манифестации СД'].isnull().sum()

# 1.
corr_matrix = data_copy[['Возраст манифестации СД', 'Возраст (на текущий момент)']].corr()
print(corr_matrix)

# 2 VIF:
from statsmodels.stats.outliers_influence import variance_inflation_factor
vif = pd.DataFrame()
vif['VIF'] = [variance_inflation_factor(data_copy[['Возраст манифестации СД', 'Возраст (на текущий момент)']].values, i)
              for i in range(2)]
vif['feature'] = ['Возраст манифестации СД', 'Возраст (на текущий момент)']
print(vif)

## 5. Длительность СД (лет)
col = 'Длительность СД (лет)'
print(col)
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')

print('\nСтатистика:')
print(data[col].describe())
data[col].value_counts()

fig, axes = plt.subplots(1, 3, figsize=(20, 5))

# Статистика для выбросов
Q1, Q3 = data[col].quantile([0.25, 0.75])
IQR = Q3 - Q1
lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR
outliers = ((data[col] < lower) | (data[col] > upper)).sum()

# 1. Ящик с усами
sns.boxplot(y=data[col], ax=axes[0])
axes[0].set_title(f'Ящик с усами: {col}')
axes[0].text(0.01, 0.9, f'Выбросы: {outliers}\nГраницы: [{lower:.1f}, {upper:.1f}]',
             transform=axes[0].transAxes, fontsize=10, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))

# 2. Гистограмма с выделением выбросов
sns.histplot(data[col], bins=20, kde=False, ax=axes[1])
# Закрашиваем области выбросов
axes[1].axvspan(data[col].min(), lower, alpha=0.3, color='red')
axes[1].axvspan(upper, data[col].max(), alpha=0.3, color='red')
axes[1].set_title(f'Гистограмма: {col}')
axes[1].set_xlabel(col)
axes[1].set_ylabel('Частота')
axes[1].text(0.05, 0.95, 'Красным выделены выбросы',
             transform=axes[1].transAxes, fontsize=9, color='red')

# 3. Плотность распределения с выделением выбросов
sns.kdeplot(data[col], fill=True, ax=axes[2])
# Закрашиваем области выбросов
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], data[col].min(), lower, color='red', alpha=0.3)
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], upper, data[col].max(), color='red', alpha=0.3)
# Линии границ
axes[2].axvline(lower, color='red', linestyle='--', alpha=0.7)
axes[2].axvline(upper, color='red', linestyle='--', alpha=0.7)
axes[2].set_title(f'Плотность распределения: {col}')
axes[2].set_xlabel(col)
axes[2].set_ylabel('Плотность')
axes[2].text(0.05, 0.95, f'Границы: {lower:.1f} | {upper:.1f}',
             transform=axes[2].transAxes, fontsize=9, color='red')

plt.tight_layout()
plt.show()

print(f"Выбросы: {outliers} из {len(data)} ({outliers/len(data)*100:.1f}%)")
print(f"Границы выбросов: [{lower:.2f}, {upper:.2f}]")

with pd.option_context('display.max_columns', None, 'display.width', None):
    nan_sd = data['Возраст манифестации СД'].isna()
    display(data[nan_sd])

"""Так я и полагал, в этих же строках три пропуска из колонки возраста манифестации, просто отсутствовали данные

### 6 - Возраст манифестации СД
"""

## 6. Возраст манифестации СД
col = 'Возраст манифестации СД'
print(col)
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')


print('\nСтатистика:')
print(data[col].describe())
data[col].value_counts()

fig, axes = plt.subplots(1, 3, figsize=(20, 5))

# Статистика для выбросов
Q1, Q3 = data[col].quantile([0.25, 0.75])
IQR = Q3 - Q1
lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR
outliers = ((data[col] < lower) | (data[col] > upper)).sum()

# 1. Ящик с усами
sns.boxplot(y=data[col], ax=axes[0])
axes[0].set_title(f'Ящик с усами: {col}')
axes[0].text(0.01, 0.9, f'Выбросы: {outliers}\nГраницы: [{lower:.1f}, {upper:.1f}]',
             transform=axes[0].transAxes, fontsize=10, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))

# 2. Гистограмма с выделением выбросов
sns.histplot(data[col], bins=20, kde=False, ax=axes[1])
# Закрашиваем области выбросов
axes[1].axvspan(data[col].min(), lower, alpha=0.3, color='red')
axes[1].axvspan(upper, data[col].max(), alpha=0.3, color='red')
axes[1].set_title(f'Гистограмма: {col}')
axes[1].set_xlabel(col)
axes[1].set_ylabel('Частота')
axes[1].text(0.05, 0.95, 'Красным выделены выбросы',
             transform=axes[1].transAxes, fontsize=9, color='red')

# 3. Плотность распределения с выделением выбросов
sns.kdeplot(data[col], fill=True, ax=axes[2])
# Закрашиваем области выбросов
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], data[col].min(), lower, color='red', alpha=0.3)
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], upper, data[col].max(), color='red', alpha=0.3)
# Линии границ
axes[2].axvline(lower, color='red', linestyle='--', alpha=0.7)
axes[2].axvline(upper, color='red', linestyle='--', alpha=0.7)
axes[2].set_title(f'Плотность распределения: {col}')
axes[2].set_xlabel(col)
axes[2].set_ylabel('Плотность')
axes[2].text(0.05, 0.95, f'Границы: {lower:.1f} | {upper:.1f}',
             transform=axes[2].transAxes, fontsize=9, color='red')

plt.tight_layout()
plt.show()

print(f"Выбросы: {outliers} из {len(data)} ({outliers/len(data)*100:.1f}%)")
print(f"Границы выбросов: [{lower:.2f}, {upper:.2f}]")

"""**ПРОПУСКИ**"""

data[data['Возраст манифестации СД'].isna()]

"""с учетом того, что мы знаем, как связаны возраст на текущий момент и колонки: длительность сд, возраст манифестации сд, мы можем заполнить медианой пропуски в манифестации, а в длительности заполним пропуски путем вычитания манифестации из возраста, чтобы получить логические значения"""

# Заполняем манифестацию медианой
data['Возраст манифестации СД'] = data['Возраст манифестации СД'].fillna(
    data['Возраст манифестации СД'].median()
)

# Заполняем длительность по формуле
mask = data['Длительность СД (лет)'].isna()
data.loc[mask, 'Длительность СД (лет)'] = (
    data.loc[mask, 'Возраст (на текущий момент)'] -
    data.loc[mask, 'Возраст манифестации СД']
)

print(f"Осталось пропусков: Длительность={data['Длительность СД (лет)'].isna().sum()}")
print(f"Осталось пропусков: Манифестация={data['Возраст манифестации СД'].isna().sum()}")

"""УДАЛЯЕМ ВОЗРАСТ МАНИФЕСТАЦИИ ИЗ_ЗА МУЛЬТИКОЛЛИНЕАРНОСТИ, по шапли анализу она менее важная

"""

data = data.drop('Возраст манифестации СД', axis=1)
data.columns

"""### 7 - Вид инсулинотерапии (1 - ручки, 2 - помпа) на момент ДКА"""

### 7. Вид инсулинотерапии (1 - ручки, 2 - помпа) на момент ДКА
col = 'Вид инсулинотерапии (1 - ручки, 2 - помпа) на момент ДКА'
data[col] = data[col].astype('category')
print(data[col].value_counts())
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')

fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# Столбчатая диаграмма с процентами
total = len(data)
value_counts = data[col].value_counts()
bars = axes[0].bar(value_counts.index.astype(str), value_counts.values)
axes[0].set_title('Распределение вида инсулинотерапии')
axes[0].set_xlabel('Вид терапии')

# Добавляем проценты
for bar, count in zip(bars, value_counts.values):
    height = bar.get_height()
    axes[0].text(bar.get_x() + bar.get_width()/2., height + 0.5,
                f'{count}\n({count/total*100:.1f}%)', ha='center')

# Круговая диаграмма
axes[1].pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%')
axes[1].set_title('Доли видов терапии')

# Столбчатая диаграмма с таргетом
sns.countplot(data=data,
              x=col,
              hue='Рецидив (0 - единичный, 1 - рецидив)',
              ax=axes[2])
axes[2].set_title('Вид терапии vs Рецидив')
axes[2].set_xlabel('Вид терапии')
axes[2].legend(title='Рецидив')

plt.tight_layout()
plt.show()

"""**Пропуски заполним самым популярным значением**"""

popular_category = data[col].value_counts().index[0]
data[col] = data[col].fillna(popular_category)
data[col].isna().sum()

"""### 8 - Применение НМГ (0 - нет, 1 - да)"""

### 8. Применение НМГ (0 - нет, 1 - да)

col = 'Применение НМГ (0 - нет, 1 - да)'
print(data[col].value_counts())
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')

fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# Круговая диаграмма
value_counts = data[col].value_counts()
labels = ['Нет', 'Да']
axes[0].pie(value_counts.values, labels=labels, autopct='%1.1f%%')
axes[0].set_title('Применение НМГ')

# Столбчатая диаграмма с таргетом
sns.countplot(data=data,
              x='Применение НМГ (0 - нет, 1 - да)',
              hue='Рецидив (0 - единичный, 1 - рецидив)',
              ax=axes[1])
axes[1].set_title(col)
axes[1].set_xlabel('Применение НМГ')
axes[1].set_xticklabels(['Нет', 'Да'])
axes[1].legend(title='Рецидив')

plt.tight_layout()
plt.show()

"""**УДАЛЯЕМ**

"""

data = data.drop('Применение НМГ (0 - нет, 1 - да)', axis=1)

"""### 9 - Суточная доза инсулина"""

### 9. Суточная доза инсулина

col = 'Суточная доза инсулина'
print(col)
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')


print('\nСтатистика:')
print(data[col].describe())
data[col].value_counts()

fig, axes = plt.subplots(1, 3, figsize=(20, 5))


# Статистика для выбросов
Q1, Q3 = data[col].quantile([0.25, 0.75])
IQR = Q3 - Q1
lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR
outliers = ((data[col] < lower) | (data[col] > upper)).sum()


# 1. Ящик с усами
sns.boxplot(y=data[col], ax=axes[0])
axes[0].set_title(f'Ящик с усами: {col}')
axes[0].text(0.01, 0.9, f'Выбросы: {outliers}\nГраницы: [{lower:.1f}, {upper:.1f}]',
             transform=axes[0].transAxes, fontsize=10, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))


# 2. Гистограмма с выделением выбросов
sns.histplot(data[col], bins=20, kde=False, ax=axes[1])
# Закрашиваем области выбросов
axes[1].axvspan(data[col].min(), lower, alpha=0.3, color='red')
axes[1].axvspan(upper, data[col].max(), alpha=0.3, color='red')
axes[1].set_title(f'Гистограмма: {col}')
axes[1].set_xlabel(col)
axes[1].set_ylabel('Частота')
axes[1].text(0.05, 0.95, 'Красным выделены выбросы',
             transform=axes[1].transAxes, fontsize=9, color='red')


# 3. Плотность распределения с выделением выбросов
sns.kdeplot(data[col], fill=True, ax=axes[2])
# Закрашиваем области выбросов
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], data[col].min(), lower, color='red', alpha=0.3)
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], upper, data[col].max(), color='red', alpha=0.3)
# Линии границ
axes[2].axvline(lower, color='red', linestyle='--', alpha=0.7)
axes[2].axvline(upper, color='red', linestyle='--', alpha=0.7)
axes[2].set_title(f'Плотность распределения: {col}')
axes[2].set_xlabel(col)
axes[2].set_ylabel('Плотность')
axes[2].text(0.05, 0.95, f'Границы: {lower:.1f} | {upper:.1f}',
             transform=axes[2].transAxes, fontsize=9, color='red')


plt.tight_layout()
plt.show()


print(f"Выбросы: {outliers} из {len(data)} ({outliers/len(data)*100:.1f}%)")
print(f"Границы выбросов: [{lower:.2f}, {upper:.2f}]")

"""**РАБОТА С ПРОПУСКАМИ**"""

pd.set_option('display.max_columns', None)
data[data['Суточная доза инсулина'].isna()].head(12)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

sns.boxplot(x='Невролог', y='Суточная доза инсулина', data=data, ax=ax1)
ax1.set_title('Ящики с усами')

sns.stripplot(x='Невролог', y='Суточная доза инсулина', data=data,
              ax=ax2, alpha=0.5, jitter=True)
ax2.set_title('Точечный график (все наблюдения)')

plt.tight_layout()
plt.show()

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

sns.boxplot(x='ХБП, А', y='Суточная доза инсулина', data=data, ax=ax1)
ax1.set_title('Ящики с усами')

sns.stripplot(x='ХБП, А', y='Суточная доза инсулина', data=data,
              ax=ax2, alpha=0.5, jitter=True)
ax2.set_title('Точечный график (все наблюдения)')

plt.tight_layout()
plt.show()

# Заполняем пропуски медианами по группам ниже
data['Суточная доза инсулина'] = data['Суточная доза инсулина'].fillna(
    data.groupby('ХБП, А')['Суточная доза инсулина'].transform('median')
)

data['Суточная доза инсулина'] = data['Суточная доза инсулина'].fillna(
    data.groupby('Невролог')['Суточная доза инсулина'].transform('median')
)

data['Суточная доза инсулина'].isna().sum()

"""### 10 - Тяжелые гипогликемии в анамнезе (0 - нет, 1 - да)"""

### 10. Тяжелые гипогликемии в анамнезе (0 - нет, 1 - да)

col = 'Тяжелые гипогликемии в анамнезе (0 - нет, 1 - да)'
print(data[col].value_counts())
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')

"""квазиконстантный признак, удаляем"""

data = data.drop(col, axis=1)

"""### 11 - Количество эпизодов легких гипогликемий в неделю"""

### 11. Количество эпизодов легких гипогликемий в неделю

col = 'Количество эпизодов легких гипогликемий в неделю'
print(data[col].value_counts())
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')

"""УДАЛЕНО из-за квазиконстантности"""

data = data.drop(col, axis=1)

"""### 12 - Количество ДКА в анамнезе"""

### 12. Количество ДКА в анамнезе

col = 'Количество ДКА в анамнезе'
print(col)
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')


print('\nСтатистика:')
print(data[col].describe())
data[col].value_counts()

data[data[col]=='/']

data.loc[data[col] == '/', col] = 1

data[data[col].isna()]

popular_category = data[col].value_counts().index[0]
data[col] = data[col].fillna(popular_category)

### 12. Количество ДКА в анамнезе

col = 'Количество ДКА в анамнезе'
print(col)
data[col] = data[col].astype(int)
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')


print('\nСтатистика:')
print(data[col].describe())
data[col].value_counts()

fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# Статистика для выбросов
Q1, Q3 = data[col].quantile([0.25, 0.75])
IQR = Q3 - Q1
lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR
outliers = ((data[col] < lower) | (data[col] > upper)).sum()

# 1. Ящик с усами
sns.boxplot(y=data[col], ax=axes[0])
axes[0].set_title(f'Ящик с усами: {col}')
axes[0].text(0.05, 0.9, f'Выбросы: {outliers}\nГраницы: [{lower:.1f}, {upper:.1f}]',
             transform=axes[0].transAxes, fontsize=10, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))

# 2. Гистограмма с выделением выбросов
sns.histplot(data[col], bins=20, kde=False, ax=axes[1])
# Закрашиваем области выбросов
axes[1].axvspan(data[col].min(), lower, alpha=0.3, color='red')
axes[1].axvspan(upper, data[col].max(), alpha=0.3, color='red')
axes[1].set_title(f'Гистограмма: {col}')
axes[1].set_xlabel(col)
axes[1].set_ylabel('Частота')
axes[1].text(0.01, 0.95, 'Красным - выбросы',
             transform=axes[1].transAxes, fontsize=9, color='red')

# 3. Плотность распределения с выделением выбросов
sns.kdeplot(data[col], fill=True, ax=axes[2])
# Закрашиваем области выбросов
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], data[col].min(), lower, color='red', alpha=0.3)
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], upper, data[col].max(), color='red', alpha=0.3)
# Линии границ
axes[2].axvline(lower, color='red', linestyle='--', alpha=0.7)
axes[2].axvline(upper, color='red', linestyle='--', alpha=0.7)
axes[2].set_title(f'Плотность распределения: {col}')
axes[2].set_xlabel(col)
axes[2].set_ylabel('Плотность')
axes[2].text(0.05, 0.95, f'Границы: {lower:.1f} | {upper:.1f}',
             transform=axes[2].transAxes, fontsize=9, color='red')

plt.tight_layout()
plt.show()

print(f"Выбросы: {outliers} из {len(data)} ({outliers/len(data)*100:.1f}%)")
print(f"Границы выбросов: [{lower:.2f}, {upper:.2f}]")

"""### 13, 14- ХБП, С or A"""

print('ХБП, С')
print(f'уник. значений: {data['ХБП, С'].nunique()}')
data['ХБП, С'] = data['ХБП, С'].astype('category')
print(f'тип: {data['ХБП, С'].dtype}')
print(f'кол-во пропусков: {data['ХБП, С'].isna().sum()}')

print('\nСтатистика:')
print(data['ХБП, С'].describe(include='object'))
data['ХБП, С'].value_counts()

fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# Столбчатая диаграмма с процентами
total = len(data)
value_counts = data['ХБП, С'].value_counts()
bars = axes[0].bar(value_counts.index.astype(str), value_counts.values)
axes[0].set_title('Распределение ХБП, С')
axes[0].set_xlabel('ХБП, С')

# Добавляем проценты
for bar, count in zip(bars, value_counts.values):
    height = bar.get_height()
    axes[0].text(bar.get_x() + bar.get_width()/2., height + 0.5,
                f'{count}\n({count/total*100:.1f}%)', ha='center')

# Круговая диаграмма
axes[1].pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%')
axes[1].set_title('Доли ХБП, С')

# Столбчатая диаграмма с таргетом
sns.countplot(data=data,
              x='ХБП, С',
              hue='Рецидив (0 - единичный, 1 - рецидив)',
              ax=axes[2])
axes[2].set_title('ХБП, С vs Рецидив')
axes[2].set_xlabel('ХБП, С')
axes[2].legend(title='Рецидив')

plt.tight_layout()
plt.show()

print('ХБП, А')
print(f'уник. значений: {data['ХБП, А'].nunique()}')
data['ХБП, А'] = data['ХБП, А'].astype('category')
print(f'тип: {data['ХБП, А'].dtype}')
print(f'кол-во пропусков: {data['ХБП, А'].isna().sum()}')

print('\nСтатистика:')
print(data['ХБП, А'].describe(include='object'))
data['ХБП, А'].value_counts()

fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# Столбчатая диаграмма с процентами
total = len(data)
value_counts = data['ХБП, А'].value_counts()
bars = axes[0].bar(value_counts.index.astype(str), value_counts.values)
axes[0].set_title('Распределение ХБП, А')
axes[0].set_xlabel('ХБП, А')

# Добавляем проценты
for bar, count in zip(bars, value_counts.values):
    height = bar.get_height()
    axes[0].text(bar.get_x() + bar.get_width()/2., height + 0.5,
                f'{count}\n({count/total*100:.1f}%)', ha='center')

# Круговая диаграмма
axes[1].pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%')
axes[1].set_title('Доли ХБП, А')

# Столбчатая диаграмма с таргетом
sns.countplot(data=data,
              x='ХБП, А',
              hue='Рецидив (0 - единичный, 1 - рецидив)',
              ax=axes[2])
axes[2].set_title('ХБП, А vs Рецидив')
axes[2].set_xlabel('ХБП, А')
axes[2].legend(title='Рецидив')

plt.tight_layout()
plt.show()

"""**РАБОТА С ПРОПУСКАМИ**"""

with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', None):
    nan_ХБП = data[(data['ХБП, А'].isna()) | (data['ХБП, С'].isna())]
    display(nan_ХБП)

from sklearn.feature_selection import f_classif

# ANOVA F-value для каждого числового признака
numeric_cols = data.select_dtypes(include=[np.number]).columns
f_values, p_values = f_classif(data[numeric_cols].fillna(data[numeric_cols].median()),
                                data['ХБП, А'].fillna(data['ХБП, А'].mode()[0]))

# Топ-10 по F-value
top10_idx = np.argsort(f_values)[-10:][::-1]
print("Топ-10 числовых признаков по связи с ХБП, А (ANOVA F-value):")
for idx in top10_idx:
    print(f"{numeric_cols[idx]:30} : F={f_values[idx]:.1f}, p={p_values[idx]:.4f}")

for col in ['ХБП, С', 'ХБП, А']:
    print(f"\nЗаполняем колонку: {col}")
    print(f"Пропусков до: {data[col].isna().sum()}")

    # Заполняем по группе Невролог
    data[col] = data.groupby('Невролог')[col].transform(
        lambda x: x.fillna(x.mode()[0]) if not x.mode().empty else x
    )

    # Заполняем общим mode
    if data[col].isna().any():
        if not data[col].mode().empty:
            data[col] = data[col].fillna(data[col].mode()[0])

    print(f"Пропусков после: {data[col].isna().sum()}")

"""### 15 - Невролог

Аналогично подозревал, что пропуски невролога последуют вместе с пропуском колонки про ретинопатию.
"""

with pd.option_context('display.max_columns', None, 'display.width', None):
    nan_neurolog = data['Невролог'].isna()
    display(data[nan_neurolog])

### 15. Невролог
col = 'Невролог'
print(data[col].value_counts())
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')

fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# Круговая диаграмма
value_counts = data['Невролог'].value_counts()
labels = ['Нет', 'Да']
axes[0].pie(value_counts.values, labels=labels, autopct='%1.1f%%')
axes[0].set_title('Наличие неврологических нарушений')

# Столбчатая диаграмма с таргетом
sns.countplot(data=data,
              x='Невролог',
              hue='Рецидив (0 - единичный, 1 - рецидив)',
              ax=axes[1])
axes[1].set_title('Невролог vs Рецидив')
axes[1].set_xlabel('Неврологические нарушения')
axes[1].set_xticks([0, 1])
axes[1].set_xticklabels(['Нет', 'Да'])
axes[1].legend(title='Рецидив')

plt.tight_layout()
plt.show()

"""### 16 - Ретинопатия

"""

### 16. Ретинопатия (0 - нет, 1 - непролиферативная, 2 - препролиферативная, 3 - пролиферативная)
col = 'Ретинопатия (0 - нет, 1 - непролиферативная, 2 - препролиферативная, 3 - пролиферативная)'
data[col] = data[col].astype('category')

print(data[col].value_counts())
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')

fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# Столбчатая диаграмма с процентами
total = len(data)
value_counts = data['Ретинопатия (0 - нет, 1 - непролиферативная, 2 - препролиферативная, 3 - пролиферативная)'].value_counts()
bars = axes[0].bar(value_counts.index.astype(str), value_counts.values)
axes[0].set_title('Распределение ретинопатии')
axes[0].set_xlabel('Стадия ретинопатии')

# Добавляем проценты
for bar, count in zip(bars, value_counts.values):
    height = bar.get_height()
    axes[0].text(bar.get_x() + bar.get_width()/2., height + 0.5,
                f'{count}\n({count/total*100:.1f}%)', ha='center')

# Круговая диаграмма
axes[1].pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%')
axes[1].set_title('Доли стадий ретинопатии')

# Столбчатая диаграмма с таргетом
sns.countplot(data=data,
              x='Ретинопатия (0 - нет, 1 - непролиферативная, 2 - препролиферативная, 3 - пролиферативная)',
              hue='Рецидив (0 - единичный, 1 - рецидив)',
              ax=axes[2])
axes[2].set_title('Ретинопатия vs Рецидив')
axes[2].set_xlabel('Стадия ретинопатии')
axes[2].legend(title='Рецидив')

plt.tight_layout()
plt.show()

"""**РАБОТА С ПРОПУСКАМИ**"""

### заполняем самым популярным значением
for col in ['Ретинопатия (0 - нет, 1 - непролиферативная, 2 - препролиферативная, 3 - пролиферативная)', 'Невролог']:
    data[col] = data[col].fillna(data[col].mode()[0])

"""### 17 - Целевой HbA1c"""

### 17. Целевой HbA1c

col = 'Целевой HbA1c'
print(col)
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')


print('\nСтатистика:')
print(data[col].describe())
data[col].value_counts()

data[data['Целевой HbA1c'].isna()]

"""УДАЛИТЬ!"""

data = data.drop(col, axis=1)

"""### 18 - HbA1c"""

### 18. HbA1c

col = 'HbA1c'
print(col)
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')


print('\nСтатистика:')
print(data[col].describe())
data[col].value_counts()

fig, axes = plt.subplots(1, 3, figsize=(20, 5))

# Статистика для выбросов
Q1, Q3 = data[col].quantile([0.25, 0.75])
IQR = Q3 - Q1
lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR
outliers = ((data[col] < lower) | (data[col] > upper)).sum()

# 1. Ящик с усами
sns.boxplot(y=data[col], ax=axes[0])
axes[0].set_title(f'Ящик с усами: {col}')
axes[0].text(0.01, 0.9, f'Выбросы: {outliers}\nГраницы: [{lower:.1f}, {upper:.1f}]',
             transform=axes[0].transAxes, fontsize=10, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))

# 2. Гистограмма с выделением выбросов
sns.histplot(data[col], bins=20, kde=False, ax=axes[1])
# Закрашиваем области выбросов
axes[1].axvspan(data[col].min(), lower, alpha=0.3, color='red')
axes[1].axvspan(upper, data[col].max(), alpha=0.3, color='red')
axes[1].set_title(f'Гистограмма: {col}')
axes[1].set_xlabel(col)
axes[1].set_ylabel('Частота')
axes[1].text(0.05, 0.95, 'Красным выделены выбросы',
             transform=axes[1].transAxes, fontsize=9, color='red')

# 3. Плотность распределения с выделением выбросов
sns.kdeplot(data[col], fill=True, ax=axes[2])
# Закрашиваем области выбросов
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], data[col].min(), lower, color='red', alpha=0.3)
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], upper, data[col].max(), color='red', alpha=0.3)
# Линии границ
axes[2].axvline(lower, color='red', linestyle='--', alpha=0.7)
axes[2].axvline(upper, color='red', linestyle='--', alpha=0.7)
axes[2].set_title(f'Плотность распределения: {col}')
axes[2].set_xlabel(col)
axes[2].set_ylabel('Плотность')
axes[2].text(0.05, 0.95, f'Границы: {lower:.1f} | {upper:.1f}',
             transform=axes[2].transAxes, fontsize=9, color='red')

plt.tight_layout()
plt.show()

print(f"Выбросы: {outliers} из {len(data)} ({outliers/len(data)*100:.1f}%)")
print(f"Границы выбросов: [{lower:.2f}, {upper:.2f}]")

### посмотрим на топ 10 корреляций с HbA1c
print(data.select_dtypes(include=[np.number]).corr()[col].sort_values(key=abs, ascending=False).head(11).iloc[1:])

"""**Работа с пропусками**"""

### 2 ВАРИАНТ - ОСТАВЛЯЕМ ДФ ТОЛЬКО С ЗАПОЛНЕННЫМИ HbA1C

"""### 19 - Креатинин при поступлении"""

### 19. Креатинин при поступлении

col = 'Креатинин при поступлении'
print(col)
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')


print('\nСтатистика:')
print(data[col].describe())
data[col].value_counts()

fig, axes = plt.subplots(1, 3, figsize=(20, 5))

# Статистика для выбросов
Q1, Q3 = data[col].quantile([0.25, 0.75])
IQR = Q3 - Q1
lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR
outliers = ((data[col] < lower) | (data[col] > upper)).sum()

# 1. Ящик с усами
sns.boxplot(y=data[col], ax=axes[0])
axes[0].set_title(f'Ящик с усами: {col}')
axes[0].text(0.01, 0.9, f'Выбросы: {outliers}\nГраницы: [{lower:.1f}, {upper:.1f}]',
             transform=axes[0].transAxes, fontsize=10, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))

# 2. Гистограмма с выделением выбросов
sns.histplot(data[col], bins=20, kde=False, ax=axes[1])
# Закрашиваем области выбросов
axes[1].axvspan(data[col].min(), lower, alpha=0.3, color='red')
axes[1].axvspan(upper, data[col].max(), alpha=0.3, color='red')
axes[1].set_title(f'Гистограмма: {col}')
axes[1].set_xlabel(col)
axes[1].set_ylabel('Частота')
axes[1].text(0.05, 0.95, 'Красным выделены выбросы',
             transform=axes[1].transAxes, fontsize=9, color='red')

# 3. Плотность распределения с выделением выбросов
sns.kdeplot(data[col], fill=True, ax=axes[2])
# Закрашиваем области выбросов
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], data[col].min(), lower, color='red', alpha=0.3)
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], upper, data[col].max(), color='red', alpha=0.3)
# Линии границ
axes[2].axvline(lower, color='red', linestyle='--', alpha=0.7)
axes[2].axvline(upper, color='red', linestyle='--', alpha=0.7)
axes[2].set_title(f'Плотность распределения: {col}')
axes[2].set_xlabel(col)
axes[2].set_ylabel('Плотность')
axes[2].text(0.05, 0.95, f'Границы: {lower:.1f} | {upper:.1f}',
             transform=axes[2].transAxes, fontsize=9, color='red')

plt.tight_layout()
plt.show()

print(f"Выбросы: {outliers} из {len(data)} ({outliers/len(data)*100:.1f}%)")
print(f"Границы выбросов: [{lower:.2f}, {upper:.2f}]")

### посмотрим на топ 10 корреляций с этой колонкой
print(data.select_dtypes(include=[np.number]).corr()['Креатинин при поступлении'].sort_values(key=abs, ascending=False).head(11).iloc[1:])

"""Заполним пропуски в конце 21 пункта

### 20 - Мочевина при поступлениии
"""

### 20. Мочевина при поступлении
col = 'Мочевина при поступлении'
print(col)
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')

print('\nСтатистика:')
print(data[col].describe())
data[col].value_counts()

fig, axes = plt.subplots(1, 3, figsize=(20, 5))

# Статистика для выбросов
Q1, Q3 = data[col].quantile([0.25, 0.75])
IQR = Q3 - Q1
lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR
outliers = ((data[col] < lower) | (data[col] > upper)).sum()

# 1. Ящик с усами
sns.boxplot(y=data[col], ax=axes[0])
axes[0].set_title(f'Ящик с усами: {col}')
axes[0].text(0.01, 0.9, f'Выбросы: {outliers}\nГраницы: [{lower:.1f}, {upper:.1f}]',
             transform=axes[0].transAxes, fontsize=10, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))

# 2. Гистограмма с выделением выбросов
sns.histplot(data[col], bins=20, kde=False, ax=axes[1])
# Закрашиваем области выбросов
axes[1].axvspan(data[col].min(), lower, alpha=0.3, color='red')
axes[1].axvspan(upper, data[col].max(), alpha=0.3, color='red')
axes[1].set_title(f'Гистограмма: {col}')
axes[1].set_xlabel(col)
axes[1].set_ylabel('Частота')
axes[1].text(0.05, 0.95, 'Красным выделены выбросы',
             transform=axes[1].transAxes, fontsize=9, color='red')

# 3. Плотность распределения с выделением выбросов
sns.kdeplot(data[col], fill=True, ax=axes[2])
# Закрашиваем области выбросов
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], data[col].min(), lower, color='red', alpha=0.3)
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], upper, data[col].max(), color='red', alpha=0.3)
# Линии границ
axes[2].axvline(lower, color='red', linestyle='--', alpha=0.7)
axes[2].axvline(upper, color='red', linestyle='--', alpha=0.7)
axes[2].set_title(f'Плотность распределения: {col}')
axes[2].set_xlabel(col)
axes[2].set_ylabel('Плотность')
axes[2].text(0.05, 0.95, f'Границы: {lower:.1f} | {upper:.1f}',
             transform=axes[2].transAxes, fontsize=9, color='red')

plt.tight_layout()
plt.show()

print(f"Выбросы: {outliers} из {len(data)} ({outliers/len(data)*100:.1f}%)")
print(f"Границы выбросов: [{lower:.2f}, {upper:.2f}]")

"""Заполним пропуски в конце 21 пункта

### 21 - pH при поступлении
"""

# Проверяем
unique_vals = data[col].dropna().astype(str).unique()
for val in sorted(unique_vals):
    print(f"'{val}'")

### 21. pH при поступлении
col = 'pH при поступлении'
print(col)
data[col] = data[col].replace(' ', np.nan)
data[col] = data[col].astype('float')
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')

print('\nСтатистика:')
print(data[col].describe())
data[col].value_counts()

data.loc[data['pH при поступлении'] == 68, 'pH при поступлении'] = 6.8

fig, axes = plt.subplots(1, 3, figsize=(20, 5))

# Статистика для выбросов
Q1, Q3 = data[col].quantile([0.25, 0.75])
IQR = Q3 - Q1
lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR
outliers = ((data[col] < lower) | (data[col] > upper)).sum()

# 1. Ящик с усами
sns.boxplot(y=data[col], ax=axes[0])
axes[0].set_title(f'Ящик с усами: {col}')
axes[0].text(0.01, 0.9, f'Выбросы: {outliers}\nГраницы: [{lower:.1f}, {upper:.1f}]',
             transform=axes[0].transAxes, fontsize=10, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))

# 2. Гистограмма с выделением выбросов
sns.histplot(data[col], bins=20, kde=False, ax=axes[1])
# Закрашиваем области выбросов
axes[1].axvspan(data[col].min(), lower, alpha=0.3, color='red')
axes[1].axvspan(upper, data[col].max(), alpha=0.3, color='red')
axes[1].set_title(f'Гистограмма: {col}')
axes[1].set_xlabel(col)
axes[1].set_ylabel('Частота')
axes[1].text(0.05, 0.95, 'Красным выделены выбросы',
             transform=axes[1].transAxes, fontsize=9, color='red')

# 3. Плотность распределения с выделением выбросов
sns.kdeplot(data[col], fill=True, ax=axes[2])
# Закрашиваем области выбросов
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], data[col].min(), lower, color='red', alpha=0.3)
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], upper, data[col].max(), color='red', alpha=0.3)
# Линии границ
axes[2].axvline(lower, color='red', linestyle='--', alpha=0.7)
axes[2].axvline(upper, color='red', linestyle='--', alpha=0.7)
axes[2].set_title(f'Плотность распределения: {col}')
axes[2].set_xlabel(col)
axes[2].set_ylabel('Плотность')
axes[2].text(0.05, 0.95, f'Границы: {lower:.1f} | {upper:.1f}',
             transform=axes[2].transAxes, fontsize=9, color='red')

plt.tight_layout()
plt.show()

print(f"Выбросы: {outliers} из {len(data)} ({outliers/len(data)*100:.1f}%)")
print(f"Границы выбросов: [{lower:.2f}, {upper:.2f}]")

"""### 22 - ВЕ при поступлении"""

### 22. ВЕ при поступлении
col = 'ВЕ при поступлении'
print(col)
print(f'уник. значений: {data[col].nunique()}')
data[col] = data[col].replace(' ', np.nan)
data[col] = data[col].astype('float')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')

print('\nСтатистика:')
print(data[col].describe())
data[col].value_counts()

fig, axes = plt.subplots(1, 3, figsize=(20, 5))

# Статистика для выбросов
Q1, Q3 = data[col].quantile([0.25, 0.75])
IQR = Q3 - Q1
lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR
outliers = ((data[col] < lower) | (data[col] > upper)).sum()

# 1. Ящик с усами
sns.boxplot(y=data[col], ax=axes[0])
axes[0].set_title(f'Ящик с усами: {col}')
axes[0].text(0.01, 0.9, f'Выбросы: {outliers}\nГраницы: [{lower:.1f}, {upper:.1f}]',
             transform=axes[0].transAxes, fontsize=10, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))

# 2. Гистограмма с выделением выбросов
sns.histplot(data[col], bins=20, kde=False, ax=axes[1])
# Закрашиваем области выбросов
axes[1].axvspan(data[col].min(), lower, alpha=0.3, color='red')
axes[1].axvspan(upper, data[col].max(), alpha=0.3, color='red')
axes[1].set_title(f'Гистограмма: {col}')
axes[1].set_xlabel(col)
axes[1].set_ylabel('Частота')
axes[1].text(0.05, 0.95, 'Красным выделены выбросы',
             transform=axes[1].transAxes, fontsize=9, color='red')

# 3. Плотность распределения с выделением выбросов
sns.kdeplot(data[col], fill=True, ax=axes[2])
# Закрашиваем области выбросов
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], data[col].min(), lower, color='red', alpha=0.3)
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], upper, data[col].max(), color='red', alpha=0.3)
# Линии границ
axes[2].axvline(lower, color='red', linestyle='--', alpha=0.7)
axes[2].axvline(upper, color='red', linestyle='--', alpha=0.7)
axes[2].set_title(f'Плотность распределения: {col}')
axes[2].set_xlabel(col)
axes[2].set_ylabel('Плотность')
axes[2].text(0.05, 0.95, f'Границы: {lower:.1f} | {upper:.1f}',
             transform=axes[2].transAxes, fontsize=9, color='red')

plt.tight_layout()
plt.show()

print(f"Выбросы: {outliers} из {len(data)} ({outliers/len(data)*100:.1f}%)")
print(f"Границы выбросов: [{lower:.2f}, {upper:.2f}]")

"""Заполним пропуски в конце 21 пункта

### 23 - Лактат при поступлении
"""

### 23. Лактат при поступлении

col = 'Лактат при поступлении'
print(col)
data[col] = data[col].replace(' ', np.nan)
data[col] = data[col].astype('float')
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')


print('\nСтатистика:')
print(data[col].describe())
data[col].value_counts()

fig, axes = plt.subplots(1, 3, figsize=(20, 5))

# Статистика для выбросов
Q1, Q3 = data[col].quantile([0.25, 0.75])
IQR = Q3 - Q1
lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR
outliers = ((data[col] < lower) | (data[col] > upper)).sum()

# 1. Ящик с усами
sns.boxplot(y=data[col], ax=axes[0])
axes[0].set_title(f'Ящик с усами: {col}')
axes[0].text(0.01, 0.9, f'Выбросы: {outliers}\nГраницы: [{lower:.1f}, {upper:.1f}]',
             transform=axes[0].transAxes, fontsize=10, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))

# 2. Гистограмма с выделением выбросов
sns.histplot(data[col], bins=20, kde=False, ax=axes[1])
# Закрашиваем области выбросов
axes[1].axvspan(data[col].min(), lower, alpha=0.3, color='red')
axes[1].axvspan(upper, data[col].max(), alpha=0.3, color='red')
axes[1].set_title(f'Гистограмма: {col}')
axes[1].set_xlabel(col)
axes[1].set_ylabel('Частота')
axes[1].text(0.05, 0.95, 'Красным выделены выбросы',
             transform=axes[1].transAxes, fontsize=9, color='red')

# 3. Плотность распределения с выделением выбросов
sns.kdeplot(data[col], fill=True, ax=axes[2])
# Закрашиваем области выбросов
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], data[col].min(), lower, color='red', alpha=0.3)
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], upper, data[col].max(), color='red', alpha=0.3)
# Линии границ
axes[2].axvline(lower, color='red', linestyle='--', alpha=0.7)
axes[2].axvline(upper, color='red', linestyle='--', alpha=0.7)
axes[2].set_title(f'Плотность распределения: {col}')
axes[2].set_xlabel(col)
axes[2].set_ylabel('Плотность')
axes[2].text(0.05, 0.95, f'Границы: {lower:.1f} | {upper:.1f}',
             transform=axes[2].transAxes, fontsize=9, color='red')

plt.tight_layout()
plt.show()

print(f"Выбросы: {outliers} из {len(data)} ({outliers/len(data)*100:.1f}%)")
print(f"Границы выбросов: [{lower:.2f}, {upper:.2f}]")

"""### 24 - Глюкоза при поступлении"""

### 24. Глюкоза при поступлении

col = 'Глюкоза при поступлении'
print(col)
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')


print('\nСтатистика:')
print(data[col].describe())
data[col].value_counts()

fig, axes = plt.subplots(1, 3, figsize=(20, 5))

# Статистика для выбросов
Q1, Q3 = data[col].quantile([0.25, 0.75])
IQR = Q3 - Q1
lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR
outliers = ((data[col] < lower) | (data[col] > upper)).sum()

# 1. Ящик с усами
sns.boxplot(y=data[col], ax=axes[0])
axes[0].set_title(f'Ящик с усами: {col}')
axes[0].text(0.01, 0.9, f'Выбросы: {outliers}\nГраницы: [{lower:.1f}, {upper:.1f}]',
             transform=axes[0].transAxes, fontsize=10, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))

# 2. Гистограмма с выделением выбросов
sns.histplot(data[col], bins=20, kde=False, ax=axes[1])
# Закрашиваем области выбросов
axes[1].axvspan(data[col].min(), lower, alpha=0.3, color='red')
axes[1].axvspan(upper, data[col].max(), alpha=0.3, color='red')
axes[1].set_title(f'Гистограмма: {col}')
axes[1].set_xlabel(col)
axes[1].set_ylabel('Частота')
axes[1].text(0.05, 0.95, 'Красным выделены выбросы',
             transform=axes[1].transAxes, fontsize=9, color='red')

# 3. Плотность распределения с выделением выбросов
sns.kdeplot(data[col], fill=True, ax=axes[2])
# Закрашиваем области выбросов
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], data[col].min(), lower, color='red', alpha=0.3)
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], upper, data[col].max(), color='red', alpha=0.3)
# Линии границ
axes[2].axvline(lower, color='red', linestyle='--', alpha=0.7)
axes[2].axvline(upper, color='red', linestyle='--', alpha=0.7)
axes[2].set_title(f'Плотность распределения: {col}')
axes[2].set_xlabel(col)
axes[2].set_ylabel('Плотность')
axes[2].text(0.05, 0.95, f'Границы: {lower:.1f} | {upper:.1f}',
             transform=axes[2].transAxes, fontsize=9, color='red')

plt.tight_layout()
plt.show()

print(f"Выбросы: {outliers} из {len(data)} ({outliers/len(data)*100:.1f}%)")
print(f"Границы выбросов: [{lower:.2f}, {upper:.2f}]")

# Визуализация матрицы корреляций
numeric_data = data.select_dtypes(include=[np.number])
plt.figure(figsize=(12, 10))
sns.heatmap(numeric_data.corr(), annot=True, fmt='.2f', cmap='coolwarm',
            center=0, square=True, linewidths=.5, cbar_kws={"shrink": .8})
plt.title('Матрица корреляций числовых признаков')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

data[(data['Креатинин при поступлении'].isna())|(data['Мочевина при поступлении'].isna())|(data['pH при поступлении'].isna())|(data['ВЕ при поступлении'].isna())|(data['Глюкоза при поступлении'].isna())]

"""**ДЛЯ ВСЕХ КОЛОНОК, ОТВЕЧАЮЩИХ ЗА АНАЛИЗЫ ПРИ ПОСТУПЛЕНИИ, ЗАПОЛНЯЕМ ПРОПУСКИ МЕДИАНОЙ**"""

# Список колонок
cols = ['Креатинин при поступлении', 'Мочевина при поступлении', 'Лактат при поступлении',
        'pH при поступлении', 'ВЕ при поступлении', 'Глюкоза при поступлении']

# Заполняем медианой
data[cols] = data[cols].fillna(data[cols].median())

# Проверяем
print("Пропусков после:", data[cols].isna().sum().sum())

"""### 25 - Общий холестерин"""

## 25. Общий холестерин

col = 'Общий холестерин'
print(col)
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')

print('\nСтатистика:')
print(data[col].describe())
data[col].value_counts()

fig, axes = plt.subplots(1, 3, figsize=(20, 5))

# Статистика для выбросов
Q1, Q3 = data[col].quantile([0.25, 0.75])
IQR = Q3 - Q1
lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR
outliers = ((data[col] < lower) | (data[col] > upper)).sum()

# 1. Ящик с усами
sns.boxplot(y=data[col], ax=axes[0])
axes[0].set_title(f'Ящик с усами: {col}')
axes[0].text(0.01, 0.9, f'Выбросы: {outliers}\nГраницы: [{lower:.1f}, {upper:.1f}]',
             transform=axes[0].transAxes, fontsize=10, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))

# 2. Гистограмма с выделением выбросов
sns.histplot(data[col], bins=20, kde=False, ax=axes[1])
# Закрашиваем области выбросов
axes[1].axvspan(data[col].min(), lower, alpha=0.3, color='red')
axes[1].axvspan(upper, data[col].max(), alpha=0.3, color='red')
axes[1].set_title(f'Гистограмма: {col}')
axes[1].set_xlabel(col)
axes[1].set_ylabel('Частота')
axes[1].text(0.05, 0.95, 'Красным выделены выбросы',
             transform=axes[1].transAxes, fontsize=9, color='red')

# 3. Плотность распределения с выделением выбросов
sns.kdeplot(data[col], fill=True, ax=axes[2])
# Закрашиваем области выбросов
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], data[col].min(), lower, color='red', alpha=0.3)
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], upper, data[col].max(), color='red', alpha=0.3)
# Линии границ
axes[2].axvline(lower, color='red', linestyle='--', alpha=0.7)
axes[2].axvline(upper, color='red', linestyle='--', alpha=0.7)
axes[2].set_title(f'Плотность распределения: {col}')
axes[2].set_xlabel(col)
axes[2].set_ylabel('Плотность')
axes[2].text(0.05, 0.95, f'Границы: {lower:.1f} | {upper:.1f}',
             transform=axes[2].transAxes, fontsize=9, color='red')

plt.tight_layout()
plt.show()

print(f"Выбросы: {outliers} из {len(data)} ({outliers/len(data)*100:.1f}%)")
print(f"Границы выбросов: [{lower:.2f}, {upper:.2f}]")

data.sort_values('Общий холестерин', ascending=False).head(20)

print(data.select_dtypes(include=[np.number]).corr()['Общий холестерин'].sort_values(key=abs, ascending=False).head(11).iloc[1:])

"""**ПРОПУСКИ**"""

# медианой пропуск заполняем
data['Общий холестерин'] = data['Общий холестерин'].fillna(data['Общий холестерин'].median())

# Проверяем
print("Пропусков после:", data['Общий холестерин'].isna().sum().sum())

"""### 26 - ЛПНП"""

## 26. ЛПНП

col = 'ЛПНП'
print(col)
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')

print('\nСтатистика:')
print(data[col].describe())
data[col].value_counts()

fig, axes = plt.subplots(1, 3, figsize=(20, 5))

# Статистика для выбросов
Q1, Q3 = data[col].quantile([0.25, 0.75])
IQR = Q3 - Q1
lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR
outliers = ((data[col] < lower) | (data[col] > upper)).sum()

# 1. Ящик с усами
sns.boxplot(y=data[col], ax=axes[0])
axes[0].set_title(f'Ящик с усами: {col}')
axes[0].text(0.01, 0.9, f'Выбросы: {outliers}\nГраницы: [{lower:.1f}, {upper:.1f}]',
             transform=axes[0].transAxes, fontsize=10, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))

# 2. Гистограмма с выделением выбросов
sns.histplot(data[col], bins=20, kde=False, ax=axes[1])
# Закрашиваем области выбросов
axes[1].axvspan(data[col].min(), lower, alpha=0.3, color='red')
axes[1].axvspan(upper, data[col].max(), alpha=0.3, color='red')
axes[1].set_title(f'Гистограмма: {col}')
axes[1].set_xlabel(col)
axes[1].set_ylabel('Частота')
axes[1].text(0.05, 0.95, 'Красным выделены выбросы',
             transform=axes[1].transAxes, fontsize=9, color='red')

# 3. Плотность распределения с выделением выбросов
sns.kdeplot(data[col], fill=True, ax=axes[2])
# Закрашиваем области выбросов
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], data[col].min(), lower, color='red', alpha=0.3)
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], upper, data[col].max(), color='red', alpha=0.3)
# Линии границ
axes[2].axvline(lower, color='red', linestyle='--', alpha=0.7)
axes[2].axvline(upper, color='red', linestyle='--', alpha=0.7)
axes[2].set_title(f'Плотность распределения: {col}')
axes[2].set_xlabel(col)
axes[2].set_ylabel('Плотность')
axes[2].text(0.05, 0.95, f'Границы: {lower:.1f} | {upper:.1f}',
             transform=axes[2].transAxes, fontsize=9, color='red')

plt.tight_layout()
plt.show()

print(f"Выбросы: {outliers} из {len(data)} ({outliers/len(data)*100:.1f}%)")
print(f"Границы выбросов: [{lower:.2f}, {upper:.2f}]")

"""### 27 - ЛПВП"""

## 27. ЛПВП

col = 'ЛПВП'
print(col)
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')

print('\nСтатистика:')
print(data[col].describe())
data[col].value_counts()

fig, axes = plt.subplots(1, 3, figsize=(20, 5))

# Статистика для выбросов
Q1, Q3 = data[col].quantile([0.25, 0.75])
IQR = Q3 - Q1
lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR
outliers = ((data[col] < lower) | (data[col] > upper)).sum()

# 1. Ящик с усами
sns.boxplot(y=data[col], ax=axes[0])
axes[0].set_title(f'Ящик с усами: {col}')
axes[0].text(0.01, 0.9, f'Выбросы: {outliers}\nГраницы: [{lower:.1f}, {upper:.1f}]',
             transform=axes[0].transAxes, fontsize=10, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))

# 2. Гистограмма с выделением выбросов
sns.histplot(data[col], bins=20, kde=False, ax=axes[1])
# Закрашиваем области выбросов
axes[1].axvspan(data[col].min(), lower, alpha=0.3, color='red')
axes[1].axvspan(upper, data[col].max(), alpha=0.3, color='red')
axes[1].set_title(f'Гистограмма: {col}')
axes[1].set_xlabel(col)
axes[1].set_ylabel('Частота')
axes[1].text(0.05, 0.95, 'Красным выделены выбросы',
             transform=axes[1].transAxes, fontsize=9, color='red')

# 3. Плотность распределения с выделением выбросов
sns.kdeplot(data[col], fill=True, ax=axes[2])
# Закрашиваем области выбросов
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], data[col].min(), lower, color='red', alpha=0.3)
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], upper, data[col].max(), color='red', alpha=0.3)
# Линии границ
axes[2].axvline(lower, color='red', linestyle='--', alpha=0.7)
axes[2].axvline(upper, color='red', linestyle='--', alpha=0.7)
axes[2].set_title(f'Плотность распределения: {col}')
axes[2].set_xlabel(col)
axes[2].set_ylabel('Плотность')
axes[2].text(0.05, 0.95, f'Границы: {lower:.1f} | {upper:.1f}',
             transform=axes[2].transAxes, fontsize=9, color='red')

plt.tight_layout()
plt.show()

print(f"Выбросы: {outliers} из {len(data)} ({outliers/len(data)*100:.1f}%)")
print(f"Границы выбросов: [{lower:.2f}, {upper:.2f}]")

data.sort_values('ЛПВП', ascending=False)

data[data['ЛПВП'].isna()]

"""у колонок ЛПНП	ЛПВП	ТГ пропуски одновременно

### 28 - ТГ
"""

## 28. ТГ

col = 'ТГ'
print(col)
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')

print('\nСтатистика:')
print(data[col].describe())
data[col].value_counts()

fig, axes = plt.subplots(1, 3, figsize=(20, 5))

# Статистика для выбросов
Q1, Q3 = data[col].quantile([0.25, 0.75])
IQR = Q3 - Q1
lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR
outliers = ((data[col] < lower) | (data[col] > upper)).sum()

# 1. Ящик с усами
sns.boxplot(y=data[col], ax=axes[0])
axes[0].set_title(f'Ящик с усами: {col}')
axes[0].text(0.01, 0.9, f'Выбросы: {outliers}\nГраницы: [{lower:.1f}, {upper:.1f}]',
             transform=axes[0].transAxes, fontsize=10, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))

# 2. Гистограмма с выделением выбросов
sns.histplot(data[col], bins=20, kde=False, ax=axes[1])
# Закрашиваем области выбросов
axes[1].axvspan(data[col].min(), lower, alpha=0.3, color='red')
axes[1].axvspan(upper, data[col].max(), alpha=0.3, color='red')
axes[1].set_title(f'Гистограмма: {col}')
axes[1].set_xlabel(col)
axes[1].set_ylabel('Частота')
axes[1].text(0.05, 0.95, 'Красным выделены выбросы',
             transform=axes[1].transAxes, fontsize=9, color='red')

# 3. Плотность распределения с выделением выбросов
sns.kdeplot(data[col], fill=True, ax=axes[2])
# Закрашиваем области выбросов
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], data[col].min(), lower, color='red', alpha=0.3)
axes[2].fill_betweenx([0, axes[2].get_ylim()[1]], upper, data[col].max(), color='red', alpha=0.3)
# Линии границ
axes[2].axvline(lower, color='red', linestyle='--', alpha=0.7)
axes[2].axvline(upper, color='red', linestyle='--', alpha=0.7)
axes[2].set_title(f'Плотность распределения: {col}')
axes[2].set_xlabel(col)
axes[2].set_ylabel('Плотность')
axes[2].text(0.05, 0.95, f'Границы: {lower:.1f} | {upper:.1f}',
             transform=axes[2].transAxes, fontsize=9, color='red')

plt.tight_layout()
plt.show()

print(f"Выбросы: {outliers} из {len(data)} ({outliers/len(data)*100:.1f}%)")
print(f"Границы выбросов: [{lower:.2f}, {upper:.2f}]")

data.sort_values('ТГ', ascending=False)

cols = ['ЛПНП', 'ЛПВП', 'ТГ']

# Заполняем медианой
data[cols] = data[cols].fillna(data[cols].median())

# Проверяем
print("Пропусков после:", data[cols].isna().sum().sum())

"""### 29 - Степень тяжести ДКА"""

## 29. Степень тяжести ДКА

col = 'Степень тяжести ДКА'
print(data[col].value_counts())
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')

data['Степень тяжести ДКА'] = data['Степень тяжести ДКА'].astype('category')

fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# Столбчатая диаграмма с процентами
total = len(data)
value_counts = data['Степень тяжести ДКА'].value_counts()
bars = axes[0].bar(value_counts.index.astype(str), value_counts.values)
axes[0].set_title('Распределение степени тяжести ДКА')
axes[0].set_xlabel('Степень тяжести')

# Добавляем проценты
for bar, count in zip(bars, value_counts.values):
    height = bar.get_height()
    axes[0].text(bar.get_x() + bar.get_width()/2., height + 0.5,
                f'{count}\n({count/total*100:.1f}%)', ha='center')

# Круговая диаграмма
axes[1].pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%')
axes[1].set_title('Доли степеней тяжести')

# Столбчатая диаграмма с таргетом
sns.countplot(data=data,
              x='Степень тяжести ДКА',
              hue='Рецидив (0 - единичный, 1 - рецидив)',
              ax=axes[2])
axes[2].set_title('Степень тяжести vs Рецидив')
axes[2].set_xlabel('Степень тяжести')
axes[2].legend(title='Рецидив')

plt.tight_layout()
plt.show()

"""**РАБОТА С ПРОПУСКАМИ**"""

# ANOVA F-value для каждого числового признака
numeric_cols = data.select_dtypes(include=[np.number]).columns
f_values, p_values = f_classif(data[numeric_cols].fillna(data[numeric_cols].median()),
                                data['Степень тяжести ДКА'].fillna(data['Степень тяжести ДКА'].mode()[0]))

# Топ-10 по F-value
top10_idx = np.argsort(f_values)[-10:][::-1]
print("Топ-10 числовых признаков по связи с 'Степень тяжести ДКА' (ANOVA F-value):")
for idx in top10_idx:
    print(f"{numeric_cols[idx]:30} : F={f_values[idx]:.1f}, p={p_values[idx]:.4f}")

fig, axes = plt.subplots(1, 2, figsize=(12, 4))

# 1. ящики
sns.boxplot(x='Степень тяжести ДКА', y='Креатинин при поступлении', data=data, ax=axes[0])
axes[0].set_title('Креатинин ↑ = тяжесть ДКА ↑')

# 2. Точечный график
sns.stripplot(x='Степень тяжести ДКА', y='Креатинин при поступлении', data=data, ax=axes[1], alpha=0.7)
axes[1].set_title('Все наблюдения')

plt.tight_layout()
plt.show()

"""Пропуски будем заполнять в зависимости от квантилей анализа ph при поступлении"""

data['Креатинин_квантиль'] = pd.qcut(data['Креатинин при поступлении'], 4)

# 1. Таблица распределения
print("Частота степеней тяжести по квантилям Креатинин:")
print(pd.crosstab(data['Креатинин_квантиль'], data['Степень тяжести ДКА']))

# 2. Самая частая степень
print("\nСамая частая степень тяжести в каждом квантиле:")
print(data.groupby('Креатинин_квантиль', observed=True)['Степень тяжести ДКА'].agg(lambda x: x.mode()[0]))

map_dict = data.groupby('Креатинин_квантиль', observed=True)['Степень тяжести ДКА'].agg(lambda x: x.mode()[0]).to_dict()
data['Степень тяжести ДКА'] = data['Степень тяжести ДКА'].fillna(data['Креатинин_квантиль'].map(map_dict)).fillna(data['Степень тяжести ДКА'].mode()[0])
data = data.drop('Креатинин_квантиль', axis=1)

print(f"Пропусков после заполнения: {data['Степень тяжести ДКА'].isna().sum()}")
print(f"\nРаспределение:")
print(data['Степень тяжести ДКА'].value_counts())

"""### 30 - Алкоголь за сутки до ДКА (0 - нет, 1 - да)"""

## 30 . Алкоголь за сутки до ДКА (0 - нет, 1 - да)

col = 'Алкоголь за сутки до ДКА (0 - нет, 1 - да)'
print(data[col].value_counts())
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')

fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# Круговая диаграмма
value_counts = data['Алкоголь за сутки до ДКА (0 - нет, 1 - да)'].value_counts()
labels = ['Нет', 'Да']
axes[0].pie(value_counts.values, labels=labels, autopct='%1.1f%%')
axes[0].set_title('Алкоголь за сутки до ДКА')

# Столбчатая диаграмма с таргетом
sns.countplot(data=data,
              x='Алкоголь за сутки до ДКА (0 - нет, 1 - да)',
              hue='Рецидив (0 - единичный, 1 - рецидив)',
              ax=axes[1])
axes[1].set_title('Алкоголь vs Рецидив')
axes[1].set_xlabel('Алкоголь')
axes[1].set_xticks([0, 1])
axes[1].set_xticklabels(['Нет', 'Да'])
axes[1].legend(title='Рецидив')

plt.tight_layout()
plt.show()

"""**ПРОПУСКИ**"""

mode_alco = data['Алкоголь за сутки до ДКА (0 - нет, 1 - да)'].mode()[0]
data['Алкоголь за сутки до ДКА (0 - нет, 1 - да)'] = data['Алкоголь за сутки до ДКА (0 - нет, 1 - да)'].fillna(mode_alco)

"""### 31 - Алкоголь за сутки до ДКА (0 - нет, 1 - да)"""

data = data.drop('Употребление ПАВ за сутки до ДКА (0-нет, 1 - да)', axis=1)

"""### TARGET - задача бинарной классификации, меняем тип таргета"""

### задача бинарной классификации, меняем тип таргета
data['Рецидив (0 - единичный, 1 - рецидив)'] = data['Рецидив (0 - единичный, 1 - рецидив)'].astype(bool)

col = 'Рецидив (0 - единичный, 1 - рецидив)'
print(data[col].value_counts())
print(f'уник. значений: {data[col].nunique()}')
print(f'тип: {data[col].dtype}')
print(f'кол-во пропусков: {data[col].isna().sum()}')

"""### Заполнение пропусков для HbA1c"""

### 1 ВАРИАНТ - имитируем заполнение
from sklearn.impute import KNNImputer

# Выбираем признаки, связанные с HbA1c
features_for_impute = ['ЛПВП', 'Алкоголь за сутки до ДКА (0 - нет, 1 - да)',
                       'Длительность СД (лет)', 'ТГ', 'Мочевина при поступлении']

# 1. Сохраняем индексы пропусков ДО импутации
missing_mask = data['HbA1c'].isna()
print(f"Пропусков в HbA1c ДО импутации: {missing_mask.sum()} ({missing_mask.mean()*100:.1f}%)")

# 2. Создаем временный датафрейм для KNN
temp_data = data[['HbA1c'] + features_for_impute].copy()

# 3. Запускаем KNN
imputer = KNNImputer(n_neighbors=5, weights='distance')
temp_data_imputed_array = imputer.fit_transform(temp_data)

# 4. Преобразуем обратно в DataFrame
temp_data_imputed = pd.DataFrame(
    temp_data_imputed_array,
    columns=['HbA1c'] + features_for_impute,
    index=temp_data.index
)

# 5. Заменяем ТОЛЬКО пропущенные значения
data.loc[missing_mask, 'HbA1c'] = temp_data_imputed.loc[missing_mask, 'HbA1c']

# 6. Проверяем результат
print(f"\nРЕЗУЛЬТАТ:")
print(f"Метод: KNNImputer (n_neighbors=5, weights='distance')")
print(f"Признаки для импутации: {', '.join(features_for_impute)}")
print(f"Заполнено значений: {missing_mask.sum()}")
print(f"Пропусков ПОСЛЕ импутации: {data['HbA1c'].isna().sum()}")

# ГИСТОГРАММА
print(f"\n{'='*50}")
print("ГИСТОГРАММА РАСПРЕДЕЛЕНИЙ")
print('='*50)

# Подготовка данных
original_values = temp_data.loc[~missing_mask, 'HbA1c']  # исходные непустые
filled_values = data.loc[missing_mask, 'HbA1c']          # заполненные KNN
all_values_after = data['HbA1c']                         # все значения после импутации

# Создаем гистограмму
fig, axes = plt.subplots(1, 3, figsize=(15, 4))

# Определяем общие границы для всех графиков
all_data = np.concatenate([original_values, filled_values])
x_min, x_max = all_data.min() * 0.9, all_data.max() * 1.1
bins = np.linspace(x_min, x_max, 20)

# 1. Исходные значения (без пропусков)
axes[0].hist(original_values, bins=bins, alpha=0.7, color='blue', edgecolor='black')
axes[0].set_title('Исходные значения\n(без пропусков)', fontweight='bold')
axes[0].set_xlabel('HbA1c (%)')
axes[0].set_ylabel('Количество')
axes[0].grid(True, alpha=0.3)

# 2. Заполненные значения
axes[1].hist(filled_values, bins=bins, alpha=0.7, color='green', edgecolor='black')
axes[1].set_title('Заполненные значения\n(KNN импутация)', fontweight='bold')
axes[1].set_xlabel('HbA1c (%)')
axes[1].set_ylabel('Количество')
axes[1].grid(True, alpha=0.3)

# 3. Все значения после импутации
axes[2].hist(all_values_after, bins=bins, alpha=0.7, color='red', edgecolor='black')
axes[2].set_title('Все значения\n(после импутации)', fontweight='bold')
axes[2].set_xlabel('HbA1c (%)')
axes[2].set_ylabel('Количество')
axes[2].grid(True, alpha=0.3)

plt.suptitle('РАСПРЕДЕЛЕНИЕ HbA1c ДО И ПОСЛЕ ИМПУТАЦИИ', fontsize=12, fontweight='bold')
plt.tight_layout()
plt.show()

# Статистика
print(f"\nСТАТИСТИКА:")
print(f"{'':<20} {'Исходные':<12} {'Заполненные':<12} {'Все после':<12}")
print("-" * 56)
print(f"{'Количество':<20} {len(original_values):<12} {len(filled_values):<12} {len(all_values_after):<12}")
print(f"{'Среднее':<20} {original_values.mean():<12.2f} {filled_values.mean():<12.2f} {all_values_after.mean():<12.2f}")
print(f"{'Медиана':<20} {original_values.median():<12.2f} {filled_values.median():<12.2f} {all_values_after.median():<12.2f}")
print(f"{'Станд. откл.':<20} {original_values.std():<12.2f} {filled_values.std():<12.2f} {all_values_after.std():<12.2f}")

"""Проверка на пропуски"""

data.isnull().sum()

"""Меняем формат колонок, где это осталось необходимо"""

data.dtypes

data[['Возраст (на текущий момент)', 'Длительность СД (лет)']] = data[['Возраст (на текущий момент)', 'Длительность СД (лет)']].astype(int)
data['Невролог'] = data['Невролог'].astype(bool)
data['Алкоголь за сутки до ДКА (0 - нет, 1 - да)'] = data['Алкоголь за сутки до ДКА (0 - нет, 1 - да)'].astype(bool)

"""## ВЫБРОСЫ

"""

df = data.copy()

num_cols = df.select_dtypes(include=[np.number]).columns

outliers = {}

for col in num_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR

    outliers[col] = df[
        (df[col] < lower) | (df[col] > upper)
    ][col].count()

outliers

"""после заполнения пропусков выбросов стало больше из-за увеличения пиковых значений в распределениях

Удалим только аномалии. Выбросы, найденные через метод IQR, оставим, так как выборка очень мала. Аномалии находили у колонок:
1. HbA1c
2. Общий холестерин
3. ЛПНП
4. ЛПВП
"""

fig, axes = plt.subplots(1, 4, figsize=(15, 5))
cols = ['HbA1c', 'Общий холестерин','ЛПНП','ЛПНП']

for i, col in enumerate(cols):
    sns.boxplot(y=df[col], ax=axes[i])
    axes[i].set_title(col)

plt.tight_layout()
plt.show()

### удаление аномалий, можно удалить по очереди, так как это все 3 разные строки
### 1. HbA1c
max_val_hba1c = df['HbA1c'].max()
df = df[df['HbA1c'] != max_val_hba1c]

### 2. Общий холестерин
top_2_chol = df['Общий холестерин'].nlargest(2).values
df = df[~df['Общий холестерин'].isin(top_2_chol)]

### 3. ЛПНП
max_val_ldl = df['ЛПНП'].max()
df = df[df['ЛПНП'] != max_val_ldl]

### 4. ЛПВП
max_val_hdl = df['ЛПВП'].max()
df = df[df['ЛПВП'] != max_val_hdl]

fig, axes = plt.subplots(1, 4, figsize=(15, 5))
cols = ['HbA1c', 'Общий холестерин','ЛПНП','ЛПНП']

for i, col in enumerate(cols):
    sns.boxplot(y=df[col], ax=axes[i])
    axes[i].set_title(col)

plt.tight_layout()
plt.show()

"""## Стандартизируем данные"""

numeric_cols = df.select_dtypes(include=[np.number]).columns
numeric_cols = numeric_cols.drop(['Количество ДКА в анамнезе'])
numeric_cols

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df_scaled = df.copy()
df_scaled[numeric_cols] = scaler.fit_transform(df[numeric_cols])

df_scaled

"""## OHE"""

categorical_columns = df_scaled.loc[:,data.dtypes=='category'].columns
categorical_columns

df_scaled_ohe = df_scaled.copy()
for col in categorical_columns:
    one_hot = pd.get_dummies(df_scaled_ohe[col], prefix=col, drop_first=True)
    df_scaled_ohe = pd.concat((df_scaled_ohe.drop(col, axis=1), one_hot), axis=1)
df_scaled_ohe

df_scaled

"""## ОБУЧЕНИЕ 1 вариант"""

df = df_scaled_ohe
df

df.shape

X = df.drop('Рецидив (0 - единичный, 1 - рецидив)', axis=1)
y = df['Рецидив (0 - единичный, 1 - рецидив)']


# Разделение данных
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Модели
models = {
    'CatBoost': CatBoostClassifier(iterations=100, depth=3, verbose=0, random_state=42),
    'XGBoost': XGBClassifier(n_estimators=100, max_depth=3, random_state=42),
    'RandomForest': RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42),
    'LogRegression': LogisticRegression(max_iter=5000, random_state=42)
}

# Оценка моделей
for name, model in models.items():
    print(f"\n{'='*50}\n{name}\n{'='*50}")

    # Кросс-валидация на трейне (4 фолда)
    cv_preds = cross_val_predict(model, X_train, y_train, cv=4, method='predict')
    cv_proba = cross_val_predict(model, X_train, y_train, cv=4, method='predict_proba')[:, 1]

    print("Кросс-валидация на трейне:")
    print(f"AUC: {roc_auc_score(y_train, cv_proba):.3f}")
    print(classification_report(y_train, cv_preds, target_names=['0', '1']))

    # Обучение и оценка на тесте
    model.fit(X_train, y_train)
    test_preds = model.predict(X_test)
    test_proba = model.predict_proba(X_test)[:, 1]

    print("Предсказание на тесте:")
    print(f"AUC: {roc_auc_score(y_test, test_proba):.3f}")
    print(classification_report(y_test, test_preds, target_names=['0', '1']))

"""#### подбор гиперпараметров"""

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import roc_auc_score, classification_report, f1_score

# Параметры для GridSearch
param_grids = {
    'CatBoost': {
        'iterations': [100, 200, 300],
        'depth': [2, 3, 4, 5, 6],
        'learning_rate': [0.001, 0.01, 0.05, 0.1, 1],
        'l2_leaf_reg': [1, 3, 5, 10],
        'border_count': [16, 32, 64, 128],
        'random_state': [42]
    },
    'XGBoost': {
        'n_estimators': [100, 200, 300],
        'max_depth': [2, 3, 4, 5, 6],
        'learning_rate': [0.001, 0.01, 0.05, 0.1],
        'subsample': [0.7, 0.8, 0.9, 1.0],
        'colsample_bytree': [0.7, 0.8, 0.9, 1.0],
        'gamma': [0, 0.1, 0.5, 1],
        'random_state': [42]
    },
    'RandomForest': {
        'n_estimators': [100, 200, 300],
        'max_depth': [None, 3, 5, 7, 10],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4],
        'max_features': ['sqrt', 'log2'],
        'class_weight': ['balanced', None],
        'random_state': [42]
    },
    'LogRegression': {
        'C': [0.001, 0.01, 0.1, 1, 10, 100],
        'penalty': ['l1', 'l2'],
        'solver': ['liblinear', 'saga'],
        'max_iter': [1000, 2000],
        'class_weight': ['balanced', None],
        'random_state': [42]
    }
}

# Гридсерч для каждой модели
best_models = {}
test_scores = {}
test_f1_scores = {}

for name, model in models.items():
    print(f"\n{'='*50}\nGridSearch для {name}\n{'='*50}")

    grid_search = GridSearchCV(
        estimator=model,
        param_grid=param_grids[name],
        cv=4,
        scoring='roc_auc',
        n_jobs=-1,
        verbose=1
    )

    grid_search.fit(X_train, y_train)
    best_models[name] = grid_search.best_estimator_

    # Оценка на тесте
    test_preds = best_models[name].predict(X_test)
    test_proba = best_models[name].predict_proba(X_test)[:, 1]

    test_auc = roc_auc_score(y_test, test_proba)
    test_f1 = f1_score(y_test, test_preds, pos_label=1)  # F1 для класса 1

    test_scores[name] = test_auc
    test_f1_scores[name] = test_f1

    print(f"Лучшие параметры: {grid_search.best_params_}")
    print(f"Лучший AUC (CV): {grid_search.best_score_:.3f}")
    print(f"AUC на тесте: {test_auc:.3f}")
    print(f"F1-score (класс 1) на тесте: {test_f1:.3f}")

    # Выводим classification report
    print(f"\nClassification Report для {name}:")
    print(classification_report(y_test, test_preds))

# Лучшая модель по F1-score для класса 1
best_model_name_f1 = max(test_f1_scores, key=test_f1_scores.get)
print(f"\n{'='*50}")
print(f"Лучшая модель по F1-score (класс 1): {best_model_name_f1}")
print(f"F1-score (класс 1): {test_f1_scores[best_model_name_f1]:.3f}")
print(f"AUC этой модели: {test_scores[best_model_name_f1]:.3f}")

# Также выводим лучшую по AUC для сравнения
best_model_name_auc = max(test_scores, key=test_scores.get)
print(f"\nЛучшая модель по AUC: {best_model_name_auc}")
print(f"AUC: {test_scores[best_model_name_auc]:.3f}")
print(f"F1-score (класс 1): {test_f1_scores[best_model_name_auc]:.3f}")

# Бутстрэп на всех данных
n = 100
aucs = {name: [] for name in models}

for i in range(n):
    X_boot, y_boot = resample(X, y, random_state=i)
    oob_idx = X.index.difference(X_boot.index)
    X_oob, y_oob = X.loc[oob_idx], y.loc[oob_idx]

    for name, model in models.items():
        m = model.__class__(**model.get_params())
        m.fit(X_boot, y_boot)
        aucs[name].append(roc_auc_score(y_oob, m.predict_proba(X_oob)[:, 1]))

# Результаты
print("БУТСТРЭП (100 итераций):")
print("Модель: Средний_AUC ± Стандартное_отклонение и 95%_доверительный_интервал")
for name, scores in aucs.items():
    mean = np.mean(scores)
    std = np.std(scores)
    ci_low, ci_high = np.percentile(scores, [2.5, 97.5])
    print(f"{name}: {mean:.3f} ± {std:.3f} [{ci_low:.3f}-{ci_high:.3f}]")

"""Посмотрим на самые важные признаки"""

# Обучение CatBoost
best_model = CatBoostClassifier(iterations=100, depth=3, verbose=0, random_state=42)
best_model.fit(X_train, y_train)

# Получение важности признаков
feature_importance = best_model.get_feature_importance()
feature_names = X.columns

# Создание DataFrame и сортировка
importance_df = pd.DataFrame({
    'feature': feature_names,
    'importance': feature_importance
}).sort_values('importance', ascending=False).head(10)

# Построение графика
plt.figure(figsize=(10, 6))
plt.barh(importance_df['feature'][::-1], importance_df['importance'][::-1])
plt.xlabel('Важность признака')
plt.title('Топ-10 важных признаков CatBoost')
plt.tight_layout()
plt.show()

# Создаем сводную таблицу
pivot_df = df.groupby(['Количество ДКА в анамнезе', 'Рецидив (0 - единичный, 1 - рецидив)']).size().reset_index(name='count')

# Строим график
plt.figure(figsize=(12, 6))
sns.barplot(data=pivot_df, x='Количество ДКА в анамнезе', y='count',
            hue='Рецидив (0 - единичный, 1 - рецидив)',
            hue_order=[0, 1])
plt.title('Распределение рецидивистов по количеству ДКА в анамнезе')
plt.xlabel('Количество ДКА в анамнезе')
plt.ylabel('Количество пациентов')
plt.legend(title='Рецидив', labels=['Единичный (0)', 'Рецидив (1)'])
plt.show()

"""Посмотрим на количество рецедивистов в каждом из значений количества дка в анамнезе"""

data.groupby(['Количество ДКА в анамнезе', 'Рецидив (0 - единичный, 1 - рецидив)']).size()

"""фича **'количество дка в анамнезе'** показательно демонстрирует мешочки нашей таргетной переменной так, что при 1 почти все пациенты - это нерецидивисты, а при 2 и больше наоборот почти все рецидивисты

### SHAP анализ 1 вариант
"""

# Обучаем лучшую модель
best_model = CatBoostClassifier(iterations=100, depth=3, verbose=0, random_state=42)
best_model.fit(X_train, y_train)

# Инициализируем SHAP explainer
explainer = shap.TreeExplainer(best_model)

# Вычисляем SHAP значения
shap_values = explainer.shap_values(X_train)

# Проверяем размерность
print(f"Размерность shap_values: {shap_values.shape}")

# 1. Summary plot - глобальная важность признаков
feat_names = list(X_train.columns)
shap.plots.violin(shap_values, feature_names=feat_names, plot_size=0.5, max_display=10)

# 2. beeswarm plot
shap.plots.beeswarm(shap.Explanation(values=shap_values,
                                     base_values=explainer.expected_value,
                                     data=X_train,
                                     feature_names=feat_names),
                    max_display=20,
                    plot_size=0.5)

# 3. Численные значения важности
shap_importance = pd.DataFrame({
    'feature': X_train.columns,
    'shap_importance': np.abs(shap_values).mean(axis=0)
}).sort_values('shap_importance', ascending=False)

print("\nТоп-10 важных признаков по SHAP:")
print(shap_importance.head(10))

# 4. Waterfall plot
shap.waterfall_plot(shap.Explanation(values=shap_values[20],
                                     base_values=explainer.expected_value,
                                     data=X_train.iloc[20],
                                     feature_names=feat_names),
                    max_display=15,
                    show=False)
plt.tight_layout()
plt.show()

"""## Обучение 2 вариант"""

X = df.drop(['Рецидив (0 - единичный, 1 - рецидив)', 'Количество ДКА в анамнезе'], axis=1)
y = df['Рецидив (0 - единичный, 1 - рецидив)']


# Разделение данных
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Модели
models = {
    'CatBoost': CatBoostClassifier(iterations=100, depth=3, verbose=0, random_state=42),
    'XGBoost': XGBClassifier(n_estimators=100, max_depth=3, random_state=42),
    'RandomForest': RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42),
    'LogRegression': LogisticRegression(max_iter=5000, random_state=42)
}

# Оценка моделей
for name, model in models.items():
    print(f"\n{'='*50}\n{name}\n{'='*50}")

    # Кросс-валидация на трейне (4 фолда)
    cv_preds = cross_val_predict(model, X_train, y_train, cv=4, method='predict')
    cv_proba = cross_val_predict(model, X_train, y_train, cv=4, method='predict_proba')[:, 1]

    print("Кросс-валидация на трейне:")
    print(f"AUC: {roc_auc_score(y_train, cv_proba):.3f}")
    print(classification_report(y_train, cv_preds, target_names=['0', '1']))

    # Обучение и оценка на тесте
    model.fit(X_train, y_train)
    test_preds = model.predict(X_test)
    test_proba = model.predict_proba(X_test)[:, 1]

    print("Предсказание на тесте:")
    print(f"AUC: {roc_auc_score(y_test, test_proba):.3f}")
    print(classification_report(y_test, test_preds, target_names=['0', '1']))

y.value_counts(normalize=True).round(3)

"""### Жадный алгоритм"""

from sklearn.model_selection import cross_val_predict
from sklearn.metrics import roc_auc_score, f1_score
from sklearn.ensemble import RandomForestClassifier
import numpy as np

rf = RandomForestClassifier(
    n_estimators=100,
    max_depth=3,
    random_state=42
)

features = list(X_train.columns)
selected_features = []

print("Жадный отбор признаков:\n")

for step in range(1, 35):
    best_feature = None
    best_auc = 0
    best_f1 = 0

    for feature in features:
        candidate_features = selected_features + [feature]

        proba = cross_val_predict(
            rf,
            X_train[candidate_features],
            y_train,
            cv=4,
            method='predict_proba'
        )[:, 1]

        preds = (proba >= 0.5).astype(int)

        auc = roc_auc_score(y_train, proba)
        f1 = f1_score(y_train, preds)

        if auc > best_auc:
            best_auc = auc
            best_f1 = f1
            best_feature = feature

    selected_features.append(best_feature)
    features.remove(best_feature)

    print(
        f"{step:2d} колонок | "
        f"добавлена: {best_feature} | "
        f"AUC = {best_auc:.3f} | "
        f"F1 = {best_f1:.3f}"
    )

"""до добавления 12 колонки еще наблюдается прирост качества, поэтому оставим их, а также группы тех колонок, что были отобраны, чтобы сохранить их интерпретируемость"""

df_greedy = df[['Суточная доза инсулина', 'Вид инсулинотерапии (1 - ручки, 2 - помпа) на момент ДКА_1.0', 'Вид инсулинотерапии (1 - ручки, 2 - помпа) на момент ДКА_2.0',
               'pH при поступлении', 'ТГ', 'Невролог' ,'Глюкоза при поступлении' ,'ЛПВП' ,'HbA1c',
               'ХБП, С_1',	'ХБП, С_2',	'ХБП, С_3',	'ХБП, С_4',	'ХБП, С_5',	'ХБП, С_3b',	'ХБП, С_3а',
               'ХБП, А_1.0',	'ХБП, А_2.0',	'ХБП, А_3.0',
               'Рецидив (0 - единичный, 1 - рецидив)']]

df_greedy

X = df_greedy.drop(['Рецидив (0 - единичный, 1 - рецидив)'], axis=1)
y = df_greedy['Рецидив (0 - единичный, 1 - рецидив)']


# Разделение данных
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Модели
models = {
    'CatBoost': CatBoostClassifier(iterations=100, depth=3, verbose=0, random_state=42),
    'XGBoost': XGBClassifier(n_estimators=100, max_depth=3, random_state=42),
    'RandomForest': RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42),
    'LogRegression': LogisticRegression(max_iter=5000, random_state=42)
}

# Оценка моделей
for name, model in models.items():
    print(f"\n{'='*50}\n{name}\n{'='*50}")

    # Кросс-валидация на трейне (4 фолда)
    cv_preds = cross_val_predict(model, X_train, y_train, cv=4, method='predict')
    cv_proba = cross_val_predict(model, X_train, y_train, cv=4, method='predict_proba')[:, 1]

    print("Кросс-валидация на трейне:")
    print(f"AUC: {roc_auc_score(y_train, cv_proba):.3f}")
    print(classification_report(y_train, cv_preds, target_names=['0', '1']))

    # Обучение и оценка на тесте
    model.fit(X_train, y_train)
    test_preds = model.predict(X_test)
    test_proba = model.predict_proba(X_test)[:, 1]

    print("Предсказание на тесте:")
    print(f"AUC: {roc_auc_score(y_test, test_proba):.3f}")
    print(classification_report(y_test, test_preds, target_names=['0', '1']))

"""#### Подбор гиперпараметров"""

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import roc_auc_score, classification_report, f1_score

# Параметры для GridSearch
param_grids = {
    'CatBoost': {
        'iterations': [100, 200, 300],
        'depth': [2, 3, 4, 5, 6],
        'learning_rate': [0.001, 0.01, 0.05, 0.1, 1],
        'l2_leaf_reg': [1, 3, 5, 10],
        'border_count': [16, 32, 64, 128],
        'random_state': [42]
    },
    'XGBoost': {
        'n_estimators': [100, 200, 300],
        'max_depth': [2, 3, 4, 5, 6],
        'learning_rate': [0.001, 0.01, 0.05, 0.1],
        'subsample': [0.7, 0.8, 0.9, 1.0],
        'colsample_bytree': [0.7, 0.8, 0.9, 1.0],
        'gamma': [0, 0.1, 0.5, 1],
        'random_state': [42]
    },
    'RandomForest': {
        'n_estimators': [100, 200, 300],
        'max_depth': [None, 3, 5, 7, 10],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4],
        'max_features': ['sqrt', 'log2'],
        'class_weight': ['balanced', None],
        'random_state': [42]
    },
    'LogRegression': {
        'C': [0.001, 0.01, 0.1, 1, 10, 100],
        'penalty': ['l1', 'l2'],
        'solver': ['liblinear', 'saga'],
        'max_iter': [1000, 2000],
        'class_weight': ['balanced', None],
        'random_state': [42]
    }
}

# Гридсерч для каждой модели
best_models = {}
test_scores = {}
test_f1_scores = {}

for name, model in models.items():
    print(f"\n{'='*50}\nGridSearch для {name}\n{'='*50}")

    grid_search = GridSearchCV(
        estimator=model,
        param_grid=param_grids[name],
        cv=4,
        scoring='roc_auc',
        n_jobs=-1,
        verbose=1
    )

    grid_search.fit(X_train, y_train)
    best_models[name] = grid_search.best_estimator_

    # Оценка на тесте
    test_preds = best_models[name].predict(X_test)
    test_proba = best_models[name].predict_proba(X_test)[:, 1]

    test_auc = roc_auc_score(y_test, test_proba)
    test_f1 = f1_score(y_test, test_preds, pos_label=1)  # F1 для класса 1

    test_scores[name] = test_auc
    test_f1_scores[name] = test_f1

    print(f"Лучшие параметры: {grid_search.best_params_}")
    print(f"Лучший AUC (CV): {grid_search.best_score_:.3f}")
    print(f"AUC на тесте: {test_auc:.3f}")
    print(f"F1-score (класс 1) на тесте: {test_f1:.3f}")

    # Выводим classification report
    print(f"\nClassification Report для {name}:")
    print(classification_report(y_test, test_preds))

# Лучшая модель по F1-score для класса 1
best_model_name_f1 = max(test_f1_scores, key=test_f1_scores.get)
print(f"\n{'='*50}")
print(f"Лучшая модель по F1-score (класс 1): {best_model_name_f1}")
print(f"F1-score (класс 1): {test_f1_scores[best_model_name_f1]:.3f}")
print(f"AUC этой модели: {test_scores[best_model_name_f1]:.3f}")

# Также выводим лучшую по AUC для сравнения
best_model_name_auc = max(test_scores, key=test_scores.get)
print(f"\nЛучшая модель по AUC: {best_model_name_auc}")
print(f"AUC: {test_scores[best_model_name_auc]:.3f}")
print(f"F1-score (класс 1): {test_f1_scores[best_model_name_auc]:.3f}")

y_pred = best_models[best_model_name_f1].predict(X_test)
print(f"лучшая модель: {best_model_name_f1} (AUC: {test_scores[best_model_name_f1]:.3f})")
print(classification_report(y_test, y_pred))

y_pred = best_models[best_model_name_auc].predict(X_test)
print(f"лучшая модель: {best_model_name_auc} (AUC: {test_scores[best_model_name_auc]:.3f})")
print(classification_report(y_test, y_pred))

"""#### SHAP анализ 2 вариант без ДКА"""

# Лучшая модель (RandomForest)
best_model = best_models[best_model_name_auc]

# SHAP explainer для RandomForest
explainer = shap.TreeExplainer(best_model)

# Вычисляем SHAP значения
shap_values = explainer.shap_values(X_train)

# Проверяем размерность
print(f"Размерность shap_values: {shap_values.shape}")

# Summary plot

# Для класса 1 (рецидив)
shap.plots.violin(shap_values[:, :, 1], feature_names=X_train.columns, max_display=10, title="SHAP для класса 1 (рецидив)")

# 2. beeswarm plot
# Для бинарной классификации берем SHAP значения для класса 1 (рецидив)
shap_values_class1 = shap_values[:, :, 1]

# Beeswarm plot для класса 1
shap.plots.beeswarm(shap.Explanation(values=shap_values_class1,
                                     base_values=explainer.expected_value[1],
                                     data=X_train,
                                     feature_names=X_train.columns),
                    max_display=20,
                    plot_size=(10, 6))

# 3. Численные значения важности
shap_importance = pd.DataFrame({
    'feature': X_train.columns,
    'shap_importance': np.abs(shap_values_class1).mean(axis=0)
}).sort_values('shap_importance', ascending=False)

print("\nТоп-10 важных признаков по SHAP:")
print(shap_importance.head(10))

# 4. Waterfall plot
shap.waterfall_plot(shap.Explanation(values=shap_values_class1[20],
                                     base_values=explainer.expected_value[1],
                                     data=X_train.iloc[20],
                                     feature_names=feat_names),
                    max_display=15,
                    show=False)
plt.tight_layout()
plt.show()

"""### ЭКСПЕРТНОЕ СОСТАВЛЕНИЕ КОЛОНОК"""

df

df_expert = df.drop(['Невролог','Креатинин при поступлении','Мочевина при поступлении','ЛПВП','Степень тяжести ДКА_2.0','Степень тяжести ДКА_3.0','Количество ДКА в анамнезе'], axis=1)
df_expert

X = df_expert.drop(['Рецидив (0 - единичный, 1 - рецидив)'], axis=1)
y = df_expert['Рецидив (0 - единичный, 1 - рецидив)']


# Разделение данных
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Модели
models = {
    'CatBoost': CatBoostClassifier(iterations=100, depth=3, verbose=0, random_state=42),
    'XGBoost': XGBClassifier(n_estimators=100, max_depth=3, random_state=42),
    'RandomForest': RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42),
    'LogRegression': LogisticRegression(max_iter=5000, random_state=42)
}

# Оценка моделей
for name, model in models.items():
    print(f"\n{'='*50}\n{name}\n{'='*50}")

    # Кросс-валидация на трейне (4 фолда)
    cv_preds = cross_val_predict(model, X_train, y_train, cv=4, method='predict')
    cv_proba = cross_val_predict(model, X_train, y_train, cv=4, method='predict_proba')[:, 1]

    print("Кросс-валидация на трейне:")
    print(f"AUC: {roc_auc_score(y_train, cv_proba):.3f}")
    print(classification_report(y_train, cv_preds, target_names=['0', '1']))

    # Обучение и оценка на тесте
    model.fit(X_train, y_train)
    test_preds = model.predict(X_test)
    test_proba = model.predict_proba(X_test)[:, 1]

    print("Предсказание на тесте:")
    print(f"AUC: {roc_auc_score(y_test, test_proba):.3f}")
    print(classification_report(y_test, test_preds, target_names=['0', '1']))

"""#### Подбор гиперпараметров"""

# Параметры для GridSearch
param_grids = {
    'CatBoost': {
        'iterations': [100, 200, 300],
        'depth': [2, 3, 4, 5, 6],
        'learning_rate': [0.001, 0.01, 0.05, 0.1, 1],
        'l2_leaf_reg': [1, 3, 5, 10],
        'border_count': [16, 32, 64, 128],
        'random_state': [42]
    },
    'XGBoost': {
        'n_estimators': [100, 200, 300],
        'max_depth': [2, 3, 4, 5, 6],
        'learning_rate': [0.001, 0.01, 0.05, 0.1],
        'subsample': [0.7, 0.8, 0.9, 1.0],
        'colsample_bytree': [0.7, 0.8, 0.9, 1.0],
        'gamma': [0, 0.1, 0.5, 1],
        'random_state': [42]
    },
    'RandomForest': {
        'n_estimators': [100, 200, 300],
        'max_depth': [None, 3, 5, 7, 10],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4],
        'max_features': ['sqrt', 'log2'],
        'class_weight': ['balanced', None],
        'random_state': [42]
    },
    'LogRegression': {
        'C': [0.001, 0.01, 0.1, 1, 10, 100],
        'penalty': ['l1', 'l2'],
        'solver': ['liblinear', 'saga'],
        'max_iter': [1000, 2000],
        'class_weight': ['balanced', None],
        'random_state': [42]
    }
}

# Гридсерч для каждой модели
best_models = {}
test_scores = {}
test_f1_scores = {}

for name, model in models.items():
    print(f"\n{'='*50}\nGridSearch для {name}\n{'='*50}")

    grid_search = GridSearchCV(
        estimator=model,
        param_grid=param_grids[name],
        cv=4,
        scoring='roc_auc',
        n_jobs=-1,
        verbose=1
    )

    grid_search.fit(X_train, y_train)
    best_models[name] = grid_search.best_estimator_

    # Оценка на тесте
    test_preds = best_models[name].predict(X_test)
    test_proba = best_models[name].predict_proba(X_test)[:, 1]

    test_auc = roc_auc_score(y_test, test_proba)
    test_f1 = f1_score(y_test, test_preds, pos_label=1)  # F1 для класса 1

    test_scores[name] = test_auc
    test_f1_scores[name] = test_f1

    print(f"Лучшие параметры: {grid_search.best_params_}")
    print(f"Лучший AUC (CV): {grid_search.best_score_:.3f}")
    print(f"AUC на тесте: {test_auc:.3f}")
    print(f"F1-score (класс 1) на тесте: {test_f1:.3f}")

    # Выводим classification report
    print(f"\nClassification Report для {name}:")
    print(classification_report(y_test, test_preds))

# Лучшая модель по F1-score для класса 1
best_model_name_f1 = max(test_f1_scores, key=test_f1_scores.get)
print(f"\n{'='*50}")
print(f"Лучшая модель по F1-score (класс 1): {best_model_name_f1}")
print(f"F1-score (класс 1): {test_f1_scores[best_model_name_f1]:.3f}")
print(f"AUC этой модели: {test_scores[best_model_name_f1]:.3f}")

# Также выводим лучшую по AUC для сравнения
best_model_name_auc = max(test_scores, key=test_scores.get)
print(f"\nЛучшая модель по AUC: {best_model_name_auc}")
print(f"AUC: {test_scores[best_model_name_auc]:.3f}")
print(f"F1-score (класс 1): {test_f1_scores[best_model_name_auc]:.3f}")

"""#### SHAP анализ 2 вариант без ДКА"""

# Лучшая модель
best_model = best_models[best_model_name_auc]

# SHAP explainer для RandomForest
explainer = shap.TreeExplainer(best_model)

# Вычисляем SHAP значения
shap_values = explainer.shap_values(X_train)

# Проверяем размерность
print(f"Размерность shap_values: {shap_values.shape}")

# Summary plot

# Для класса 1 (рецидив)
shap.plots.violin(shap_values[:, :, 1], feature_names=X_train.columns, max_display=10, title="SHAP для класса 1 (рецидив)")

# 2. beeswarm plot
# Для бинарной классификации берем SHAP значения для класса 1 (рецидив)
shap_values_class1 = shap_values[:, :, 1]

# Beeswarm plot для класса 1
shap.plots.beeswarm(shap.Explanation(values=shap_values_class1,
                                     base_values=explainer.expected_value[1],
                                     data=X_train,
                                     feature_names=X_train.columns),
                    max_display=20,
                    plot_size=(10, 6))

# 3. Численные значения важности
shap_importance = pd.DataFrame({
    'feature': X_train.columns,
    'shap_importance': np.abs(shap_values_class1).mean(axis=0)
}).sort_values('shap_importance', ascending=False)

print("\nТоп-10 важных признаков по SHAP:")
print(shap_importance.head(10))

# 4. Waterfall plot
shap.waterfall_plot(shap.Explanation(values=shap_values_class1[20],
                                     base_values=explainer.expected_value[1],
                                     data=X_train.iloc[20],
                                     feature_names=feat_names),
                    max_display=15,
                    show=False)
plt.tight_layout()
plt.show()

